{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/farnoush\n"
     ]
    }
   ],
   "source": [
    "cd /work/farnoush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular_df = data.loc[:, \"molecular_weight\":\"covalent_unit_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=25, random_state=42).fit(molecular_df)\n",
    "cluster_labels = pd.Series(kmeans.labels_)\n",
    "tmp = cluster_labels.value_counts()\n",
    "tmp = tmp / tmp.sum()\n",
    "tmp = tmp.sample(frac=1, random_state=30).cumsum()\n",
    "train_clusters = set(tmp[lambda x: x<.80].index)\n",
    "test_clusters = set(tmp[lambda x: x>=.80].index)\n",
    "train_mol = molecular_df.iloc[cluster_labels[lambda s: s.map(lambda x: x in train_clusters)].index]\n",
    "test_mol = molecular_df.iloc[cluster_labels[lambda s: s.map(lambda x: x in test_clusters)].index]\n",
    "\n",
    "train_test_split = pd.concat([\n",
    "    train_mol[[]].reset_index().assign(type=\"train\"),\n",
    "    test_mol[[]].reset_index().assign(type=\"test\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['type'] = 'Neither'\n",
    "\n",
    "# Check if the values in DataFrame A exist in DataFrame B\n",
    "mask_B = data.loc[:, \"molecular_weight\": \"covalent_unit_count\"].isin(train_mol).all(axis=1)\n",
    "data.loc[mask_B, 'type'] = 'train'\n",
    "\n",
    "mask_C = data.loc[:, \"molecular_weight\": \"covalent_unit_count\"].isin(test_mol).all(axis=1)\n",
    "data.loc[mask_C, 'type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'test'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "data.loc[:, \"molecular_weight\":\"covalent_unit_count\"] = scaler.fit_transform(data.loc[:, \"molecular_weight\":\"covalent_unit_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"sex_F\",\"age_group_1\"], axis = 1,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data[\"type\"] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[data[\"type\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2166501976284585"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = train.loc[:, 'sex_M':\"880\"]\n",
    "y_train = train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, 'sex_M':\"880\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.5000 - auc: 0.8063 - val_loss: 0.4603 - val_auc: 0.8208\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.4302 - auc: 0.8636 - val_loss: 0.4915 - val_auc: 0.8141\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3889 - auc: 0.8911 - val_loss: 0.4547 - val_auc: 0.8123\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3611 - auc: 0.9072 - val_loss: 0.4944 - val_auc: 0.8113\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3426 - auc: 0.9172 - val_loss: 0.4725 - val_auc: 0.8062\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3290 - auc: 0.9240 - val_loss: 0.4677 - val_auc: 0.8130\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3147 - auc: 0.9310 - val_loss: 0.4778 - val_auc: 0.8054\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.3014 - auc: 0.9368 - val_loss: 0.4895 - val_auc: 0.8076\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2950 - auc: 0.9397 - val_loss: 0.4779 - val_auc: 0.8111\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.2878 - auc: 0.9427 - val_loss: 0.4826 - val_auc: 0.8052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aaccbe86250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train = train.loc[:, 'sex_M':\"880\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, 'sex_M':\"880\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.65124579 0.79944059 0.71877277 0.73315069 0.64150312 0.66078481\n",
      " 0.70400687 0.7245919  0.70909063 0.67864147 0.66588748 0.73270201\n",
      " 0.64609231 0.66398177 0.67045824 0.61886406 0.69238712 0.72212666\n",
      " 0.60624196 0.88013285 0.72056542 0.64463618 0.65804907 0.66043195\n",
      " 0.77754158 0.70310105 0.76277519 0.72846122 0.7548942  0.65448864]\n",
      "Macro AUC: 0.6995015872267804\n",
      "MAP per class: [0.2763009  0.4006522  0.2324758  0.24824392 0.32889934 0.22249033\n",
      " 0.81356651 0.56459206 0.82699836 0.34131171 0.8142239  0.19218936\n",
      " 0.64810852 0.5661369  0.63828524 0.41273074 0.12008915 0.43286396\n",
      " 0.83088299 0.2705282  0.42242307 0.47805945 0.66050116 0.72757969\n",
      " 0.32438937 0.83273774 0.41277234 0.28507464 0.21066954 0.76992256]\n",
      "Macro MAP: 0.47685665499155017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82044744, 0.92431533, 0.88683   , 0.98812187, 0.36417222,\n",
       "        0.73984563, 0.02293885, 0.5256598 , 0.1126579 , 0.7270808 ,\n",
       "        0.15678883, 0.6152917 , 0.18926752, 0.21749508, 0.34489042,\n",
       "        0.1701901 , 0.6711427 , 0.6756826 , 0.03608501, 0.69581234,\n",
       "        0.7022246 , 0.36245036, 0.04998559, 0.11852336, 0.9152977 ,\n",
       "        0.05146474, 0.27130908, 0.33583796, 0.99279934, 0.03325117,\n",
       "        0.17955253, 0.07568464, 0.11317003, 0.0118781 , 0.6358278 ,\n",
       "        0.2601544 , 0.97706115, 0.47434023, 0.8873421 , 0.27291915,\n",
       "        0.8432112 , 0.38470826, 0.8107325 , 0.7825049 , 0.6551096 ,\n",
       "        0.8298099 , 0.3288573 , 0.3243174 , 0.963915  , 0.3041877 ,\n",
       "        0.2977754 , 0.63754964, 0.9500144 , 0.88147664, 0.08470229,\n",
       "        0.94853526, 0.7286909 , 0.66416204, 0.00720065, 0.96674883]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train= train.loc[:, 'sex_M': 'age_group_5']\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, 'sex_M': 'age_group_5']\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.5361 - auc_31: 0.7716 - val_loss: 0.4744 - val_auc_31: 0.8038\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5139 - auc_31: 0.7918 - val_loss: 0.4617 - val_auc_31: 0.8099\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5105 - auc_31: 0.7952 - val_loss: 0.4651 - val_auc_31: 0.8104\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5089 - auc_31: 0.7966 - val_loss: 0.4563 - val_auc_31: 0.8123\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5086 - auc_31: 0.7969 - val_loss: 0.4682 - val_auc_31: 0.8127\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5082 - auc_31: 0.7974 - val_loss: 0.4609 - val_auc_31: 0.8125\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5080 - auc_31: 0.7975 - val_loss: 0.4736 - val_auc_31: 0.8119\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5076 - auc_31: 0.7981 - val_loss: 0.4594 - val_auc_31: 0.8136\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5070 - auc_31: 0.7984 - val_loss: 0.4580 - val_auc_31: 0.8115\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5064 - auc_31: 0.7991 - val_loss: 0.4605 - val_auc_31: 0.8128\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5068 - auc_31: 0.7988 - val_loss: 0.4694 - val_auc_31: 0.8138\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5065 - auc_31: 0.7990 - val_loss: 0.4694 - val_auc_31: 0.8153\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5068 - auc_31: 0.7986 - val_loss: 0.4689 - val_auc_31: 0.8117\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5067 - auc_31: 0.7987 - val_loss: 0.4633 - val_auc_31: 0.8116\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5067 - auc_31: 0.7987 - val_loss: 0.4676 - val_auc_31: 0.8119\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5055 - auc_31: 0.7999 - val_loss: 0.4704 - val_auc_31: 0.8144\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5057 - auc_31: 0.7998 - val_loss: 0.4633 - val_auc_31: 0.8117\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5059 - auc_31: 0.7995 - val_loss: 0.4563 - val_auc_31: 0.8142\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5054 - auc_31: 0.8000 - val_loss: 0.4661 - val_auc_31: 0.8137\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5058 - auc_31: 0.7997 - val_loss: 0.4757 - val_auc_31: 0.8135\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5059 - auc_31: 0.7994 - val_loss: 0.4628 - val_auc_31: 0.8135\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5063 - auc_31: 0.7990 - val_loss: 0.4592 - val_auc_31: 0.8136\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5053 - auc_31: 0.8002 - val_loss: 0.4666 - val_auc_31: 0.8133\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5057 - auc_31: 0.7997 - val_loss: 0.4599 - val_auc_31: 0.8133\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5053 - auc_31: 0.8001 - val_loss: 0.4581 - val_auc_31: 0.8129\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5048 - auc_31: 0.8007 - val_loss: 0.4618 - val_auc_31: 0.8118\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5054 - auc_31: 0.8000 - val_loss: 0.4621 - val_auc_31: 0.8133\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5055 - auc_31: 0.7999 - val_loss: 0.4606 - val_auc_31: 0.8127\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5051 - auc_31: 0.8002 - val_loss: 0.4644 - val_auc_31: 0.8135\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5053 - auc_31: 0.8000 - val_loss: 0.4580 - val_auc_31: 0.8143\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5048 - auc_31: 0.8004 - val_loss: 0.4647 - val_auc_31: 0.8141\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5053 - auc_31: 0.8000 - val_loss: 0.4573 - val_auc_31: 0.8122\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8007 - val_loss: 0.4719 - val_auc_31: 0.8135\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5048 - auc_31: 0.8006 - val_loss: 0.4620 - val_auc_31: 0.8127\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5049 - auc_31: 0.8004 - val_loss: 0.4619 - val_auc_31: 0.8124\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5049 - auc_31: 0.8003 - val_loss: 0.4645 - val_auc_31: 0.8135\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5055 - auc_31: 0.7997 - val_loss: 0.4591 - val_auc_31: 0.8133\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5048 - auc_31: 0.8005 - val_loss: 0.4596 - val_auc_31: 0.8133\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8007 - val_loss: 0.4654 - val_auc_31: 0.8137\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5049 - auc_31: 0.8005 - val_loss: 0.4543 - val_auc_31: 0.8136\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5049 - auc_31: 0.8004 - val_loss: 0.4607 - val_auc_31: 0.8132\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5050 - auc_31: 0.8003 - val_loss: 0.4666 - val_auc_31: 0.8134\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8007 - val_loss: 0.4586 - val_auc_31: 0.8129\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5048 - auc_31: 0.8005 - val_loss: 0.4627 - val_auc_31: 0.8131\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5049 - auc_31: 0.8004 - val_loss: 0.4710 - val_auc_31: 0.8134\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5050 - auc_31: 0.8003 - val_loss: 0.4644 - val_auc_31: 0.8125\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5047 - auc_31: 0.8005 - val_loss: 0.4619 - val_auc_31: 0.8132\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5048 - auc_31: 0.8004 - val_loss: 0.4642 - val_auc_31: 0.8126\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5045 - auc_31: 0.8008 - val_loss: 0.4627 - val_auc_31: 0.8123\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5047 - auc_31: 0.8005 - val_loss: 0.4629 - val_auc_31: 0.8128\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8006 - val_loss: 0.4565 - val_auc_31: 0.8131\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5047 - auc_31: 0.8005 - val_loss: 0.4596 - val_auc_31: 0.8136\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8006 - val_loss: 0.4589 - val_auc_31: 0.8133\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8007 - val_loss: 0.4601 - val_auc_31: 0.8136\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8007 - val_loss: 0.4644 - val_auc_31: 0.8135\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5045 - auc_31: 0.8007 - val_loss: 0.4572 - val_auc_31: 0.8138\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5045 - auc_31: 0.8008 - val_loss: 0.4736 - val_auc_31: 0.8139\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5048 - auc_31: 0.8004 - val_loss: 0.4623 - val_auc_31: 0.8130\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5045 - auc_31: 0.8007 - val_loss: 0.4610 - val_auc_31: 0.8130\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8007 - val_loss: 0.4623 - val_auc_31: 0.8131\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5043 - auc_31: 0.8009 - val_loss: 0.4698 - val_auc_31: 0.8136\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5045 - auc_31: 0.8007 - val_loss: 0.4591 - val_auc_31: 0.8135\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5043 - auc_31: 0.8009 - val_loss: 0.4619 - val_auc_31: 0.8135\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8005 - val_loss: 0.4636 - val_auc_31: 0.8133\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5043 - auc_31: 0.8010 - val_loss: 0.4595 - val_auc_31: 0.8138\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5044 - auc_31: 0.8007 - val_loss: 0.4601 - val_auc_31: 0.8138\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8011 - val_loss: 0.4652 - val_auc_31: 0.8136\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8012 - val_loss: 0.4696 - val_auc_31: 0.8140\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5045 - auc_31: 0.8008 - val_loss: 0.4627 - val_auc_31: 0.8135\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5042 - auc_31: 0.8010 - val_loss: 0.4603 - val_auc_31: 0.8134\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5044 - auc_31: 0.8008 - val_loss: 0.4615 - val_auc_31: 0.8134\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5043 - auc_31: 0.8009 - val_loss: 0.4635 - val_auc_31: 0.8130\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8012 - val_loss: 0.4598 - val_auc_31: 0.8137\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5043 - auc_31: 0.8009 - val_loss: 0.4625 - val_auc_31: 0.8136\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5044 - auc_31: 0.8008 - val_loss: 0.4675 - val_auc_31: 0.8133\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5044 - auc_31: 0.8007 - val_loss: 0.4620 - val_auc_31: 0.8125\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8011 - val_loss: 0.4640 - val_auc_31: 0.8129\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5045 - auc_31: 0.8007 - val_loss: 0.4579 - val_auc_31: 0.8137\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5044 - auc_31: 0.8008 - val_loss: 0.4713 - val_auc_31: 0.8136\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5043 - auc_31: 0.8009 - val_loss: 0.4641 - val_auc_31: 0.8139\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5039 - auc_31: 0.8013 - val_loss: 0.4683 - val_auc_31: 0.8130\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8010 - val_loss: 0.4661 - val_auc_31: 0.8137\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5042 - auc_31: 0.8009 - val_loss: 0.4600 - val_auc_31: 0.8138\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8011 - val_loss: 0.4629 - val_auc_31: 0.8139\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8011 - val_loss: 0.4587 - val_auc_31: 0.8129\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5042 - auc_31: 0.8010 - val_loss: 0.4629 - val_auc_31: 0.8138\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5046 - auc_31: 0.8005 - val_loss: 0.4610 - val_auc_31: 0.8134\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5042 - auc_31: 0.8010 - val_loss: 0.4613 - val_auc_31: 0.8135\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5042 - auc_31: 0.8010 - val_loss: 0.4668 - val_auc_31: 0.8141\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8011 - val_loss: 0.4598 - val_auc_31: 0.8125\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5040 - auc_31: 0.8012 - val_loss: 0.4640 - val_auc_31: 0.8129\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5044 - auc_31: 0.8008 - val_loss: 0.4596 - val_auc_31: 0.8133\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5042 - auc_31: 0.8010 - val_loss: 0.4606 - val_auc_31: 0.8139\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5039 - auc_31: 0.8012 - val_loss: 0.4695 - val_auc_31: 0.8142\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5041 - auc_31: 0.8012 - val_loss: 0.4604 - val_auc_31: 0.8143\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5039 - auc_31: 0.8013 - val_loss: 0.4654 - val_auc_31: 0.8134\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5044 - auc_31: 0.8007 - val_loss: 0.4691 - val_auc_31: 0.8143\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5043 - auc_31: 0.8009 - val_loss: 0.4579 - val_auc_31: 0.8132\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5040 - auc_31: 0.8012 - val_loss: 0.4655 - val_auc_31: 0.8128\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5037 - auc_31: 0.8015 - val_loss: 0.4632 - val_auc_31: 0.8136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aac3475f810>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train= train.loc[:, 'sex_M': 'age_group_5']\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, 'sex_M': 'age_group_5']\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='tanh', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.53849881 0.57909078 0.54450263 0.51824703 0.52263798 0.54296405\n",
      " 0.54570982 0.57402657 0.56650803 0.54421526 0.5648744  0.53004963\n",
      " 0.57427917 0.55182909 0.51894082 0.56970269 0.52793999 0.56692246\n",
      " 0.57730908 0.60546682 0.59520913 0.57040013 0.55449033 0.58943269\n",
      " 0.53883077 0.57317667 0.56263549 0.51880658 0.53269187 0.52868776]\n",
      "Macro AUC: 0.5542692186499008\n",
      "MAP per class: [0.15475587 0.16402712 0.10400307 0.0517232  0.23169973 0.13582024\n",
      " 0.67724234 0.29422302 0.67657696 0.19714729 0.72335741 0.04762087\n",
      " 0.52959971 0.40000367 0.46901983 0.33909366 0.06175936 0.23387334\n",
      " 0.77409761 0.07120948 0.25324579 0.34915337 0.52613956 0.63066395\n",
      " 0.13522109 0.70546373 0.2276108  0.14480487 0.05843526 0.64955548]\n",
      "Macro MAP: 0.33390492205628264\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train= train.loc[:, 'molecular_weight': 'covalent_unit_count']\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, 'molecular_weight': 'covalent_unit_count']\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.5146 - auc_32: 0.7905 - val_loss: 0.4655 - val_auc_32: 0.8084\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5063 - auc_32: 0.7989 - val_loss: 0.4728 - val_auc_32: 0.8070\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5052 - auc_32: 0.8001 - val_loss: 0.4642 - val_auc_32: 0.8098\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5041 - auc_32: 0.8011 - val_loss: 0.4584 - val_auc_32: 0.8090\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5031 - auc_32: 0.8021 - val_loss: 0.4769 - val_auc_32: 0.8053\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5021 - auc_32: 0.8031 - val_loss: 0.4835 - val_auc_32: 0.8076\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5013 - auc_32: 0.8039 - val_loss: 0.4848 - val_auc_32: 0.8080\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5010 - auc_32: 0.8041 - val_loss: 0.4738 - val_auc_32: 0.8072\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5005 - auc_32: 0.8045 - val_loss: 0.4720 - val_auc_32: 0.8058\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4998 - auc_32: 0.8052 - val_loss: 0.4749 - val_auc_32: 0.8047\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4994 - auc_32: 0.8056 - val_loss: 0.4793 - val_auc_32: 0.8069\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4992 - auc_32: 0.8058 - val_loss: 0.4736 - val_auc_32: 0.8072\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4984 - auc_32: 0.8065 - val_loss: 0.4732 - val_auc_32: 0.8067\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4984 - auc_32: 0.8065 - val_loss: 0.4728 - val_auc_32: 0.8049\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4976 - auc_32: 0.8073 - val_loss: 0.4796 - val_auc_32: 0.8053\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4976 - auc_32: 0.8073 - val_loss: 0.4770 - val_auc_32: 0.8063\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4972 - auc_32: 0.8077 - val_loss: 0.4810 - val_auc_32: 0.8061\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4970 - auc_32: 0.8078 - val_loss: 0.4807 - val_auc_32: 0.8054\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4967 - auc_32: 0.8082 - val_loss: 0.4779 - val_auc_32: 0.8073\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4961 - auc_32: 0.8087 - val_loss: 0.4779 - val_auc_32: 0.8058\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4962 - auc_32: 0.8086 - val_loss: 0.4860 - val_auc_32: 0.8037\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4955 - auc_32: 0.8093 - val_loss: 0.4800 - val_auc_32: 0.8045\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4952 - auc_32: 0.8096 - val_loss: 0.4797 - val_auc_32: 0.8065\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4954 - auc_32: 0.8095 - val_loss: 0.4775 - val_auc_32: 0.8060\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4945 - auc_32: 0.8103 - val_loss: 0.4788 - val_auc_32: 0.8038\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4948 - auc_32: 0.8099 - val_loss: 0.4789 - val_auc_32: 0.8074\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4941 - auc_32: 0.8106 - val_loss: 0.4823 - val_auc_32: 0.8018\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4940 - auc_32: 0.8106 - val_loss: 0.4829 - val_auc_32: 0.8055\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4937 - auc_32: 0.8110 - val_loss: 0.4837 - val_auc_32: 0.8026\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4934 - auc_32: 0.8113 - val_loss: 0.4851 - val_auc_32: 0.8040\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4930 - auc_32: 0.8117 - val_loss: 0.4807 - val_auc_32: 0.8035\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4926 - auc_32: 0.8120 - val_loss: 0.4876 - val_auc_32: 0.8056\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4924 - auc_32: 0.8123 - val_loss: 0.4771 - val_auc_32: 0.8071\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4925 - auc_32: 0.8120 - val_loss: 0.4839 - val_auc_32: 0.8048\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4920 - auc_32: 0.8125 - val_loss: 0.4773 - val_auc_32: 0.8068\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4919 - auc_32: 0.8126 - val_loss: 0.4773 - val_auc_32: 0.8055\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4915 - auc_32: 0.8130 - val_loss: 0.4801 - val_auc_32: 0.8070\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4911 - auc_32: 0.8133 - val_loss: 0.4838 - val_auc_32: 0.8028\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4909 - auc_32: 0.8136 - val_loss: 0.4843 - val_auc_32: 0.8052\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4910 - auc_32: 0.8135 - val_loss: 0.4810 - val_auc_32: 0.8038\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4901 - auc_32: 0.8142 - val_loss: 0.4808 - val_auc_32: 0.8054\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4898 - auc_32: 0.8146 - val_loss: 0.4799 - val_auc_32: 0.8060\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4898 - auc_32: 0.8146 - val_loss: 0.4842 - val_auc_32: 0.7996\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4897 - auc_32: 0.8147 - val_loss: 0.4763 - val_auc_32: 0.8043\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4890 - auc_32: 0.8152 - val_loss: 0.4919 - val_auc_32: 0.8058\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4886 - auc_32: 0.8156 - val_loss: 0.4858 - val_auc_32: 0.8052\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4886 - auc_32: 0.8155 - val_loss: 0.4917 - val_auc_32: 0.8030\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4878 - auc_32: 0.8163 - val_loss: 0.4892 - val_auc_32: 0.8025\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4878 - auc_32: 0.8163 - val_loss: 0.4829 - val_auc_32: 0.8058\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4867 - auc_32: 0.8174 - val_loss: 0.4790 - val_auc_32: 0.8049\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4865 - auc_32: 0.8176 - val_loss: 0.4675 - val_auc_32: 0.8048\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4868 - auc_32: 0.8172 - val_loss: 0.4842 - val_auc_32: 0.8033\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4860 - auc_32: 0.8180 - val_loss: 0.4745 - val_auc_32: 0.8051\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4859 - auc_32: 0.8182 - val_loss: 0.4858 - val_auc_32: 0.8035\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4859 - auc_32: 0.8180 - val_loss: 0.4862 - val_auc_32: 0.8039\n",
      "Epoch 56/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4848 - auc_32: 0.8190 - val_loss: 0.4730 - val_auc_32: 0.8042\n",
      "Epoch 57/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4851 - auc_32: 0.8188 - val_loss: 0.4955 - val_auc_32: 0.8044\n",
      "Epoch 58/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4843 - auc_32: 0.8196 - val_loss: 0.4901 - val_auc_32: 0.8040\n",
      "Epoch 59/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4838 - auc_32: 0.8200 - val_loss: 0.4817 - val_auc_32: 0.8050\n",
      "Epoch 60/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4834 - auc_32: 0.8205 - val_loss: 0.4884 - val_auc_32: 0.8023\n",
      "Epoch 61/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4824 - auc_32: 0.8213 - val_loss: 0.4839 - val_auc_32: 0.8057\n",
      "Epoch 62/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4831 - auc_32: 0.8206 - val_loss: 0.4924 - val_auc_32: 0.8028\n",
      "Epoch 63/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4825 - auc_32: 0.8212 - val_loss: 0.4946 - val_auc_32: 0.8024\n",
      "Epoch 64/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4819 - auc_32: 0.8217 - val_loss: 0.4724 - val_auc_32: 0.8058\n",
      "Epoch 65/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4815 - auc_32: 0.8221 - val_loss: 0.4965 - val_auc_32: 0.8002\n",
      "Epoch 66/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4810 - auc_32: 0.8226 - val_loss: 0.4745 - val_auc_32: 0.8042\n",
      "Epoch 67/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4806 - auc_32: 0.8229 - val_loss: 0.4835 - val_auc_32: 0.8056\n",
      "Epoch 68/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4803 - auc_32: 0.8232 - val_loss: 0.4733 - val_auc_32: 0.8035\n",
      "Epoch 69/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4802 - auc_32: 0.8233 - val_loss: 0.4954 - val_auc_32: 0.8036\n",
      "Epoch 70/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4791 - auc_32: 0.8243 - val_loss: 0.4883 - val_auc_32: 0.8026\n",
      "Epoch 71/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4786 - auc_32: 0.8247 - val_loss: 0.4801 - val_auc_32: 0.8052\n",
      "Epoch 72/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4786 - auc_32: 0.8248 - val_loss: 0.5070 - val_auc_32: 0.8019\n",
      "Epoch 73/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4779 - auc_32: 0.8253 - val_loss: 0.4995 - val_auc_32: 0.8019\n",
      "Epoch 74/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4773 - auc_32: 0.8259 - val_loss: 0.4888 - val_auc_32: 0.8032\n",
      "Epoch 75/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4771 - auc_32: 0.8261 - val_loss: 0.4961 - val_auc_32: 0.8008\n",
      "Epoch 76/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4773 - auc_32: 0.8260 - val_loss: 0.4798 - val_auc_32: 0.8048\n",
      "Epoch 77/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4763 - auc_32: 0.8268 - val_loss: 0.4955 - val_auc_32: 0.8029\n",
      "Epoch 78/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4757 - auc_32: 0.8273 - val_loss: 0.4826 - val_auc_32: 0.8022\n",
      "Epoch 79/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4748 - auc_32: 0.8280 - val_loss: 0.4965 - val_auc_32: 0.8003\n",
      "Epoch 80/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4741 - auc_32: 0.8288 - val_loss: 0.4936 - val_auc_32: 0.8044\n",
      "Epoch 81/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4739 - auc_32: 0.8289 - val_loss: 0.4978 - val_auc_32: 0.8045\n",
      "Epoch 82/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4735 - auc_32: 0.8292 - val_loss: 0.4963 - val_auc_32: 0.7975\n",
      "Epoch 83/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4732 - auc_32: 0.8294 - val_loss: 0.5070 - val_auc_32: 0.8033\n",
      "Epoch 84/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4723 - auc_32: 0.8303 - val_loss: 0.5004 - val_auc_32: 0.8001\n",
      "Epoch 85/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4717 - auc_32: 0.8307 - val_loss: 0.4860 - val_auc_32: 0.8059\n",
      "Epoch 86/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4712 - auc_32: 0.8313 - val_loss: 0.5118 - val_auc_32: 0.8005\n",
      "Epoch 87/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4720 - auc_32: 0.8305 - val_loss: 0.4835 - val_auc_32: 0.8036\n",
      "Epoch 88/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4702 - auc_32: 0.8322 - val_loss: 0.5026 - val_auc_32: 0.7974\n",
      "Epoch 89/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4698 - auc_32: 0.8325 - val_loss: 0.5045 - val_auc_32: 0.8026\n",
      "Epoch 90/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4687 - auc_32: 0.8333 - val_loss: 0.4779 - val_auc_32: 0.8048\n",
      "Epoch 91/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4687 - auc_32: 0.8332 - val_loss: 0.4950 - val_auc_32: 0.8008\n",
      "Epoch 92/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4685 - auc_32: 0.8336 - val_loss: 0.5045 - val_auc_32: 0.7976\n",
      "Epoch 93/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4682 - auc_32: 0.8337 - val_loss: 0.5100 - val_auc_32: 0.7993\n",
      "Epoch 94/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4664 - auc_32: 0.8352 - val_loss: 0.5035 - val_auc_32: 0.8042\n",
      "Epoch 95/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4663 - auc_32: 0.8354 - val_loss: 0.5061 - val_auc_32: 0.7988\n",
      "Epoch 96/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4665 - auc_32: 0.8353 - val_loss: 0.4795 - val_auc_32: 0.7998\n",
      "Epoch 97/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4653 - auc_32: 0.8361 - val_loss: 0.5001 - val_auc_32: 0.8002\n",
      "Epoch 98/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4648 - auc_32: 0.8366 - val_loss: 0.4921 - val_auc_32: 0.8025\n",
      "Epoch 99/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4649 - auc_32: 0.8366 - val_loss: 0.5006 - val_auc_32: 0.8019\n",
      "Epoch 100/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4635 - auc_32: 0.8377 - val_loss: 0.4958 - val_auc_32: 0.7969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aac341b0a50>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train= train.loc[:, 'molecular_weight': 'covalent_unit_count']\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, 'molecular_weight': 'covalent_unit_count']\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.52559576 0.47931493 0.60165116 0.70692167 0.56236747 0.61108101\n",
      " 0.51377923 0.51892413 0.55061425 0.46843619 0.54917193 0.59284892\n",
      " 0.62156224 0.56923344 0.59402003 0.56729462 0.4600692  0.54064744\n",
      " 0.47800688 0.69622523 0.58929977 0.57874732 0.54578821 0.54509615\n",
      " 0.6473564  0.55266421 0.64202449 0.64855759 0.72888081 0.53867162]\n",
      "Macro AUC: 0.5741617431120347\n",
      "MAP per class: [0.17084281 0.14934416 0.13175127 0.13929403 0.25095222 0.17426806\n",
      " 0.65321411 0.25626271 0.65468575 0.18276775 0.70172979 0.07777201\n",
      " 0.55080526 0.40202442 0.53926133 0.39071398 0.05415885 0.24459376\n",
      " 0.71540433 0.12637297 0.24883878 0.39584638 0.5362571  0.61185664\n",
      " 0.18927955 0.68337051 0.25946775 0.21353901 0.17452604 0.63897437]\n",
      "Macro MAP: 0.3506058563534993\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train= train.loc[:, \"1\":\"880\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, \"1\":\"880\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5185 - auc_33: 0.7884 - val_loss: 0.4772 - val_auc_33: 0.8106\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4773 - auc_33: 0.8271 - val_loss: 0.4794 - val_auc_33: 0.8158\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4545 - auc_33: 0.8463 - val_loss: 0.4740 - val_auc_33: 0.8211\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4309 - auc_33: 0.8644 - val_loss: 0.4648 - val_auc_33: 0.8117\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4123 - auc_33: 0.8772 - val_loss: 0.4915 - val_auc_33: 0.8163\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3944 - auc_33: 0.8883 - val_loss: 0.4655 - val_auc_33: 0.8143\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3770 - auc_33: 0.8991 - val_loss: 0.4622 - val_auc_33: 0.8106\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3711 - auc_33: 0.9025 - val_loss: 0.5393 - val_auc_33: 0.8091\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3564 - auc_33: 0.9108 - val_loss: 0.4890 - val_auc_33: 0.8111\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3501 - auc_33: 0.9136 - val_loss: 0.4860 - val_auc_33: 0.8051\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3424 - auc_33: 0.9181 - val_loss: 0.5057 - val_auc_33: 0.8061\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3348 - auc_33: 0.9216 - val_loss: 0.5508 - val_auc_33: 0.8004\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3270 - auc_33: 0.9256 - val_loss: 0.5389 - val_auc_33: 0.8057\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3227 - auc_33: 0.9276 - val_loss: 0.5279 - val_auc_33: 0.7982\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3156 - auc_33: 0.9309 - val_loss: 0.5519 - val_auc_33: 0.7971\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3152 - auc_33: 0.9311 - val_loss: 0.4957 - val_auc_33: 0.8071\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3075 - auc_33: 0.9346 - val_loss: 0.5221 - val_auc_33: 0.7999\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3044 - auc_33: 0.9359 - val_loss: 0.5230 - val_auc_33: 0.7989\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3010 - auc_33: 0.9375 - val_loss: 0.5501 - val_auc_33: 0.7956\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2991 - auc_33: 0.9384 - val_loss: 0.5609 - val_auc_33: 0.7963\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2932 - auc_33: 0.9408 - val_loss: 0.5655 - val_auc_33: 0.7954\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2887 - auc_33: 0.9427 - val_loss: 0.5355 - val_auc_33: 0.8010\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2865 - auc_33: 0.9435 - val_loss: 0.5627 - val_auc_33: 0.7967\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2853 - auc_33: 0.9439 - val_loss: 0.5610 - val_auc_33: 0.7918\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2811 - auc_33: 0.9458 - val_loss: 0.5364 - val_auc_33: 0.7930\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2815 - auc_33: 0.9456 - val_loss: 0.5521 - val_auc_33: 0.7930\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2783 - auc_33: 0.9468 - val_loss: 0.5687 - val_auc_33: 0.7924\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2760 - auc_33: 0.9476 - val_loss: 0.5787 - val_auc_33: 0.7938\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2747 - auc_33: 0.9482 - val_loss: 0.5909 - val_auc_33: 0.7910\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2712 - auc_33: 0.9496 - val_loss: 0.5736 - val_auc_33: 0.7946\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2711 - auc_33: 0.9495 - val_loss: 0.5610 - val_auc_33: 0.7971\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2699 - auc_33: 0.9501 - val_loss: 0.5574 - val_auc_33: 0.7931\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2674 - auc_33: 0.9511 - val_loss: 0.5853 - val_auc_33: 0.7902\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2645 - auc_33: 0.9521 - val_loss: 0.5666 - val_auc_33: 0.7929\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2660 - auc_33: 0.9515 - val_loss: 0.5506 - val_auc_33: 0.7969\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2611 - auc_33: 0.9532 - val_loss: 0.5679 - val_auc_33: 0.7962\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2623 - auc_33: 0.9528 - val_loss: 0.5766 - val_auc_33: 0.7960\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2588 - auc_33: 0.9541 - val_loss: 0.5969 - val_auc_33: 0.7975\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2580 - auc_33: 0.9543 - val_loss: 0.5908 - val_auc_33: 0.7921\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2579 - auc_33: 0.9544 - val_loss: 0.5628 - val_auc_33: 0.7927\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2550 - auc_33: 0.9555 - val_loss: 0.5941 - val_auc_33: 0.7896\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2541 - auc_33: 0.9557 - val_loss: 0.5776 - val_auc_33: 0.7925\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2531 - auc_33: 0.9561 - val_loss: 0.6123 - val_auc_33: 0.7903\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2525 - auc_33: 0.9563 - val_loss: 0.5997 - val_auc_33: 0.7908\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2518 - auc_33: 0.9565 - val_loss: 0.5909 - val_auc_33: 0.7923\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2497 - auc_33: 0.9574 - val_loss: 0.5758 - val_auc_33: 0.7889\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2481 - auc_33: 0.9576 - val_loss: 0.5883 - val_auc_33: 0.7977\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2477 - auc_33: 0.9579 - val_loss: 0.5937 - val_auc_33: 0.7908\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2467 - auc_33: 0.9582 - val_loss: 0.6155 - val_auc_33: 0.7892\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2443 - auc_33: 0.9590 - val_loss: 0.6144 - val_auc_33: 0.7879\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2448 - auc_33: 0.9589 - val_loss: 0.6033 - val_auc_33: 0.7915\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2454 - auc_33: 0.9587 - val_loss: 0.6281 - val_auc_33: 0.7885\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2434 - auc_33: 0.9594 - val_loss: 0.6368 - val_auc_33: 0.7823\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2420 - auc_33: 0.9597 - val_loss: 0.6075 - val_auc_33: 0.7874\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2415 - auc_33: 0.9599 - val_loss: 0.6000 - val_auc_33: 0.7913\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2406 - auc_33: 0.9603 - val_loss: 0.6292 - val_auc_33: 0.7882\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2397 - auc_33: 0.9606 - val_loss: 0.6130 - val_auc_33: 0.7892\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2399 - auc_33: 0.9603 - val_loss: 0.6010 - val_auc_33: 0.7927\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2388 - auc_33: 0.9608 - val_loss: 0.6090 - val_auc_33: 0.7880\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2384 - auc_33: 0.9609 - val_loss: 0.6123 - val_auc_33: 0.7912\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2357 - auc_33: 0.9619 - val_loss: 0.5917 - val_auc_33: 0.7880\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2363 - auc_33: 0.9616 - val_loss: 0.5896 - val_auc_33: 0.7937\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2370 - auc_33: 0.9614 - val_loss: 0.6053 - val_auc_33: 0.7911\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2358 - auc_33: 0.9617 - val_loss: 0.6310 - val_auc_33: 0.7905\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2357 - auc_33: 0.9618 - val_loss: 0.6340 - val_auc_33: 0.7837\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2340 - auc_33: 0.9622 - val_loss: 0.6335 - val_auc_33: 0.7880\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2344 - auc_33: 0.9622 - val_loss: 0.6548 - val_auc_33: 0.7890\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2313 - auc_33: 0.9631 - val_loss: 0.6239 - val_auc_33: 0.7907\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2317 - auc_33: 0.9631 - val_loss: 0.6400 - val_auc_33: 0.7825\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2316 - auc_33: 0.9630 - val_loss: 0.6336 - val_auc_33: 0.7829\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2306 - auc_33: 0.9634 - val_loss: 0.6251 - val_auc_33: 0.7877\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2299 - auc_33: 0.9635 - val_loss: 0.6516 - val_auc_33: 0.7855\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2309 - auc_33: 0.9634 - val_loss: 0.6260 - val_auc_33: 0.7890\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2303 - auc_33: 0.9634 - val_loss: 0.6524 - val_auc_33: 0.7874\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2287 - auc_33: 0.9641 - val_loss: 0.6532 - val_auc_33: 0.7853\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2294 - auc_33: 0.9638 - val_loss: 0.6232 - val_auc_33: 0.7901\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2278 - auc_33: 0.9643 - val_loss: 0.6410 - val_auc_33: 0.7855\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2266 - auc_33: 0.9645 - val_loss: 0.6716 - val_auc_33: 0.7858\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2266 - auc_33: 0.9646 - val_loss: 0.6423 - val_auc_33: 0.7840\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2283 - auc_33: 0.9641 - val_loss: 0.6387 - val_auc_33: 0.7908\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2276 - auc_33: 0.9642 - val_loss: 0.6597 - val_auc_33: 0.7813\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2268 - auc_33: 0.9645 - val_loss: 0.6515 - val_auc_33: 0.7852\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2250 - auc_33: 0.9650 - val_loss: 0.6511 - val_auc_33: 0.7870\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2229 - auc_33: 0.9657 - val_loss: 0.6619 - val_auc_33: 0.7845\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2255 - auc_33: 0.9648 - val_loss: 0.6401 - val_auc_33: 0.7858\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2245 - auc_33: 0.9652 - val_loss: 0.6521 - val_auc_33: 0.7828\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2249 - auc_33: 0.9650 - val_loss: 0.6478 - val_auc_33: 0.7841\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2220 - auc_33: 0.9659 - val_loss: 0.6650 - val_auc_33: 0.7846\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2243 - auc_33: 0.9652 - val_loss: 0.6588 - val_auc_33: 0.7828\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2240 - auc_33: 0.9653 - val_loss: 0.6418 - val_auc_33: 0.7859\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2219 - auc_33: 0.9660 - val_loss: 0.6481 - val_auc_33: 0.7828\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2219 - auc_33: 0.9660 - val_loss: 0.6618 - val_auc_33: 0.7840\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2224 - auc_33: 0.9657 - val_loss: 0.6570 - val_auc_33: 0.7833\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2227 - auc_33: 0.9657 - val_loss: 0.6499 - val_auc_33: 0.7862\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2214 - auc_33: 0.9660 - val_loss: 0.6677 - val_auc_33: 0.7849\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2213 - auc_33: 0.9661 - val_loss: 0.6802 - val_auc_33: 0.7821\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2185 - auc_33: 0.9669 - val_loss: 0.6824 - val_auc_33: 0.7849\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2205 - auc_33: 0.9663 - val_loss: 0.6695 - val_auc_33: 0.7840\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2206 - auc_33: 0.9663 - val_loss: 0.6591 - val_auc_33: 0.7869\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2205 - auc_33: 0.9663 - val_loss: 0.6632 - val_auc_33: 0.7819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aad7bc59790>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train= train.loc[:, \"1\":\"880\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, \"1\":\"880\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.59447536 0.69076702 0.57474367 0.66163697 0.60158941 0.54167269\n",
      " 0.62458616 0.60901706 0.62172724 0.64633346 0.5805904  0.54200913\n",
      " 0.60711769 0.63163667 0.59004059 0.60949094 0.59843387 0.60905139\n",
      " 0.56501517 0.81669008 0.64413946 0.5704578  0.64733982 0.55278866\n",
      " 0.65986728 0.61483893 0.69585904 0.63464223 0.77534429 0.59790789]\n",
      "Macro AUC: 0.6236603454938484\n",
      "MAP per class: [0.19413961 0.32350525 0.19766574 0.40776761 0.29088083 0.16652216\n",
      " 0.75645172 0.40365039 0.75919744 0.34873856 0.74371102 0.0900767\n",
      " 0.57195532 0.47209139 0.56916824 0.40602312 0.08082869 0.31638821\n",
      " 0.78456344 0.21960971 0.35527268 0.3838237  0.61987528 0.62148711\n",
      " 0.21553595 0.75754357 0.32847586 0.2263303  0.18572657 0.70543359]\n",
      "Macro MAP: 0.416747992558999\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bio"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train= train.loc[:, \"A0A068JFB7\":\"W7JWW5\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, \"A0A068JFB7\":\"W7JWW5\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.4899 - auc_34: 0.8158 - val_loss: 0.4596 - val_auc_34: 0.8158\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3813 - auc_34: 0.8969 - val_loss: 0.4730 - val_auc_34: 0.8111\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3391 - auc_34: 0.9202 - val_loss: 0.4655 - val_auc_34: 0.8117\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3116 - auc_34: 0.9333 - val_loss: 0.4983 - val_auc_34: 0.8082\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2946 - auc_34: 0.9409 - val_loss: 0.4993 - val_auc_34: 0.8076\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2815 - auc_34: 0.9462 - val_loss: 0.5035 - val_auc_34: 0.8036\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2726 - auc_34: 0.9495 - val_loss: 0.5092 - val_auc_34: 0.8036\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2629 - auc_34: 0.9531 - val_loss: 0.5255 - val_auc_34: 0.8008\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2556 - auc_34: 0.9556 - val_loss: 0.5250 - val_auc_34: 0.8050\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2527 - auc_34: 0.9566 - val_loss: 0.5270 - val_auc_34: 0.7993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aac44d31110>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train= train.loc[:, \"A0A068JFB7\":\"W7JWW5\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, \"A0A068JFB7\":\"W7JWW5\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.64721121 0.69212878 0.68397581 0.86481164 0.66102433 0.63369937\n",
      " 0.65094028 0.67019003 0.63055932 0.59719643 0.59590554 0.91666071\n",
      " 0.60012529 0.67442536 0.69466352 0.64131354 0.63339446 0.64376194\n",
      " 0.5292332  0.70271986 0.69167612 0.6305264  0.60057763 0.61906532\n",
      " 0.79867776 0.66722109 0.69541649 0.70166853 0.75729418 0.56185823]\n",
      "Macro AUC: 0.6695974124348827\n",
      "MAP per class: [0.25494461 0.28106409 0.15471046 0.30292584 0.35642322 0.1974067\n",
      " 0.76445827 0.43954278 0.75175068 0.27038606 0.76246414 0.33608831\n",
      " 0.59962053 0.55840207 0.6104526  0.49128756 0.09642345 0.33983373\n",
      " 0.75301392 0.10476874 0.37101171 0.43015449 0.60981702 0.69612165\n",
      " 0.34299521 0.79158139 0.39591469 0.3199677  0.33925042 0.69318592]\n",
      "Macro MAP: 0.44719893235495606\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIO+DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /work/apps/python3/anaconda3/2019.10/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /work/apps/python3/anaconda3/2019.10/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:264: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "Best parameters found: {'activation': 'relu', 'batch_size': 32, 'dropout_rate': 0.7, 'epochs': 10, 'optimizer': 'adam'}\n",
      "Best AUC score: 0.6576325640256933\n",
      "AUC per class: [0.71094887 0.68020116 0.707945   0.85568987 0.63620949 0.60260138\n",
      " 0.62623361 0.66326618 0.65789544 0.62697219 0.62965854 0.87630733\n",
      " 0.61505301 0.658309   0.67449987 0.64041061 0.71058254 0.63225904\n",
      " 0.55593075 0.70628759 0.72443839 0.64123584 0.55396108 0.65698845\n",
      " 0.78376026 0.64575953 0.69507388 0.69816775 0.71444323 0.55483954]\n",
      "Average AUC: 0.6711976468708812\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.concat([train.loc[:, \"A0A068JFB7\":\"W7JWW5\"], train.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, \"A0A068JFB7\":\"W7JWW5\"], test.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.5186 - auc_2: 0.7911 - val_loss: 0.4580 - val_auc_2: 0.8187\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4071 - auc_2: 0.8804 - val_loss: 0.4597 - val_auc_2: 0.8240\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3542 - auc_2: 0.9116 - val_loss: 0.4712 - val_auc_2: 0.8190\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3228 - auc_2: 0.9276 - val_loss: 0.4744 - val_auc_2: 0.8144\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2997 - auc_2: 0.9383 - val_loss: 0.4914 - val_auc_2: 0.8127\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2820 - auc_2: 0.9456 - val_loss: 0.4948 - val_auc_2: 0.8144\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2713 - auc_2: 0.9498 - val_loss: 0.5055 - val_auc_2: 0.8092\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2603 - auc_2: 0.9540 - val_loss: 0.5135 - val_auc_2: 0.8085\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2513 - auc_2: 0.9571 - val_loss: 0.5224 - val_auc_2: 0.8071\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2451 - auc_2: 0.9593 - val_loss: 0.5268 - val_auc_2: 0.8047\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2363 - auc_2: 0.9622 - val_loss: 0.5489 - val_auc_2: 0.8065\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2320 - auc_2: 0.9634 - val_loss: 0.5611 - val_auc_2: 0.8061\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2290 - auc_2: 0.9645 - val_loss: 0.5493 - val_auc_2: 0.8073\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2252 - auc_2: 0.9655 - val_loss: 0.5604 - val_auc_2: 0.8054\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2222 - auc_2: 0.9665 - val_loss: 0.5672 - val_auc_2: 0.8020\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2166 - auc_2: 0.9683 - val_loss: 0.5768 - val_auc_2: 0.8034\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2116 - auc_2: 0.9696 - val_loss: 0.5654 - val_auc_2: 0.8046\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2100 - auc_2: 0.9701 - val_loss: 0.5818 - val_auc_2: 0.8002\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2081 - auc_2: 0.9706 - val_loss: 0.5802 - val_auc_2: 0.8013\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2069 - auc_2: 0.9710 - val_loss: 0.5879 - val_auc_2: 0.7976\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2033 - auc_2: 0.9719 - val_loss: 0.5983 - val_auc_2: 0.8041\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2006 - auc_2: 0.9727 - val_loss: 0.6061 - val_auc_2: 0.8017\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1978 - auc_2: 0.9735 - val_loss: 0.6059 - val_auc_2: 0.8009\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1962 - auc_2: 0.9739 - val_loss: 0.6047 - val_auc_2: 0.8005\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1938 - auc_2: 0.9745 - val_loss: 0.6146 - val_auc_2: 0.8011\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1920 - auc_2: 0.9750 - val_loss: 0.6218 - val_auc_2: 0.8004\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1901 - auc_2: 0.9754 - val_loss: 0.6243 - val_auc_2: 0.7996\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1883 - auc_2: 0.9759 - val_loss: 0.6194 - val_auc_2: 0.8002\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1873 - auc_2: 0.9762 - val_loss: 0.6345 - val_auc_2: 0.8007\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1880 - auc_2: 0.9760 - val_loss: 0.6210 - val_auc_2: 0.8014\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1846 - auc_2: 0.9769 - val_loss: 0.6373 - val_auc_2: 0.8002\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1848 - auc_2: 0.9767 - val_loss: 0.6458 - val_auc_2: 0.7990\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1836 - auc_2: 0.9770 - val_loss: 0.6359 - val_auc_2: 0.8001\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1817 - auc_2: 0.9776 - val_loss: 0.6384 - val_auc_2: 0.8018\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1784 - auc_2: 0.9784 - val_loss: 0.6554 - val_auc_2: 0.7980\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1777 - auc_2: 0.9785 - val_loss: 0.6518 - val_auc_2: 0.8010\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1771 - auc_2: 0.9786 - val_loss: 0.6657 - val_auc_2: 0.7993\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1765 - auc_2: 0.9788 - val_loss: 0.6632 - val_auc_2: 0.7971\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1743 - auc_2: 0.9793 - val_loss: 0.6664 - val_auc_2: 0.7959\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1730 - auc_2: 0.9797 - val_loss: 0.6819 - val_auc_2: 0.7950\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1727 - auc_2: 0.9797 - val_loss: 0.6694 - val_auc_2: 0.7976\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1727 - auc_2: 0.9797 - val_loss: 0.6759 - val_auc_2: 0.7953\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1701 - auc_2: 0.9803 - val_loss: 0.6731 - val_auc_2: 0.7978\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1701 - auc_2: 0.9803 - val_loss: 0.6762 - val_auc_2: 0.7965\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1685 - auc_2: 0.9807 - val_loss: 0.6921 - val_auc_2: 0.7930\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1701 - auc_2: 0.9803 - val_loss: 0.6929 - val_auc_2: 0.7953\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1678 - auc_2: 0.9808 - val_loss: 0.6804 - val_auc_2: 0.7971\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1660 - auc_2: 0.9813 - val_loss: 0.6899 - val_auc_2: 0.7930\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1665 - auc_2: 0.9811 - val_loss: 0.6989 - val_auc_2: 0.7962\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1670 - auc_2: 0.9809 - val_loss: 0.6964 - val_auc_2: 0.7934\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1642 - auc_2: 0.9816 - val_loss: 0.7025 - val_auc_2: 0.7940\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1619 - auc_2: 0.9821 - val_loss: 0.7121 - val_auc_2: 0.7945\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1614 - auc_2: 0.9822 - val_loss: 0.7124 - val_auc_2: 0.7943\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1609 - auc_2: 0.9823 - val_loss: 0.7166 - val_auc_2: 0.7943\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1609 - auc_2: 0.9823 - val_loss: 0.7249 - val_auc_2: 0.7939\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1608 - auc_2: 0.9823 - val_loss: 0.7180 - val_auc_2: 0.7939\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1595 - auc_2: 0.9826 - val_loss: 0.7174 - val_auc_2: 0.7938\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1581 - auc_2: 0.9829 - val_loss: 0.7356 - val_auc_2: 0.7909\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1578 - auc_2: 0.9830 - val_loss: 0.7364 - val_auc_2: 0.7925\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1578 - auc_2: 0.9830 - val_loss: 0.7362 - val_auc_2: 0.7931\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1568 - auc_2: 0.9832 - val_loss: 0.7337 - val_auc_2: 0.7928\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1572 - auc_2: 0.9831 - val_loss: 0.7443 - val_auc_2: 0.7916\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1550 - auc_2: 0.9836 - val_loss: 0.7498 - val_auc_2: 0.7922\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1546 - auc_2: 0.9837 - val_loss: 0.7455 - val_auc_2: 0.7927\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1541 - auc_2: 0.9838 - val_loss: 0.7581 - val_auc_2: 0.7909\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1535 - auc_2: 0.9839 - val_loss: 0.7613 - val_auc_2: 0.7913\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1524 - auc_2: 0.9842 - val_loss: 0.7591 - val_auc_2: 0.7909\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1511 - auc_2: 0.9844 - val_loss: 0.7706 - val_auc_2: 0.7924\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1526 - auc_2: 0.9841 - val_loss: 0.7551 - val_auc_2: 0.7917\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1526 - auc_2: 0.9841 - val_loss: 0.7546 - val_auc_2: 0.7911\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1516 - auc_2: 0.9843 - val_loss: 0.7692 - val_auc_2: 0.7912\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1516 - auc_2: 0.9843 - val_loss: 0.7685 - val_auc_2: 0.7908\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1510 - auc_2: 0.9844 - val_loss: 0.7581 - val_auc_2: 0.7911\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1497 - auc_2: 0.9847 - val_loss: 0.7675 - val_auc_2: 0.7921\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1485 - auc_2: 0.9849 - val_loss: 0.7784 - val_auc_2: 0.7909\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1486 - auc_2: 0.9849 - val_loss: 0.7767 - val_auc_2: 0.7925\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1487 - auc_2: 0.9849 - val_loss: 0.7631 - val_auc_2: 0.7911\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1485 - auc_2: 0.9849 - val_loss: 0.7719 - val_auc_2: 0.7893\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1471 - auc_2: 0.9852 - val_loss: 0.7799 - val_auc_2: 0.7934\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1470 - auc_2: 0.9853 - val_loss: 0.7890 - val_auc_2: 0.7891\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1449 - auc_2: 0.9857 - val_loss: 0.7975 - val_auc_2: 0.7890\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1466 - auc_2: 0.9853 - val_loss: 0.7913 - val_auc_2: 0.7864\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1456 - auc_2: 0.9855 - val_loss: 0.7968 - val_auc_2: 0.7900\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1460 - auc_2: 0.9854 - val_loss: 0.7966 - val_auc_2: 0.7886\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1445 - auc_2: 0.9857 - val_loss: 0.8077 - val_auc_2: 0.7874\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1449 - auc_2: 0.9856 - val_loss: 0.7971 - val_auc_2: 0.7894\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1443 - auc_2: 0.9858 - val_loss: 0.8030 - val_auc_2: 0.7878\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1444 - auc_2: 0.9857 - val_loss: 0.8023 - val_auc_2: 0.7879\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1444 - auc_2: 0.9858 - val_loss: 0.8038 - val_auc_2: 0.7876\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1429 - auc_2: 0.9860 - val_loss: 0.8124 - val_auc_2: 0.7869\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1423 - auc_2: 0.9862 - val_loss: 0.8086 - val_auc_2: 0.7886\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1428 - auc_2: 0.9861 - val_loss: 0.8097 - val_auc_2: 0.7894\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1413 - auc_2: 0.9864 - val_loss: 0.8132 - val_auc_2: 0.7905\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1410 - auc_2: 0.9864 - val_loss: 0.8007 - val_auc_2: 0.7897\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1417 - auc_2: 0.9863 - val_loss: 0.8078 - val_auc_2: 0.7862\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1399 - auc_2: 0.9866 - val_loss: 0.8162 - val_auc_2: 0.7879\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1391 - auc_2: 0.9868 - val_loss: 0.8182 - val_auc_2: 0.7893\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1406 - auc_2: 0.9865 - val_loss: 0.8111 - val_auc_2: 0.7888\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1387 - auc_2: 0.9869 - val_loss: 0.8311 - val_auc_2: 0.7877\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1410 - auc_2: 0.9864 - val_loss: 0.8275 - val_auc_2: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aacc378d0d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train = pd.concat([train.loc[:, \"A0A068JFB7\":\"W7JWW5\"], train.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, \"A0A068JFB7\":\"W7JWW5\"], test.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.61883617 0.65563372 0.64484852 0.7786027  0.6269024  0.57792708\n",
      " 0.6627769  0.68186519 0.63259221 0.64134414 0.61406288 0.76647211\n",
      " 0.63057331 0.62395966 0.64280964 0.67060193 0.55929533 0.59910156\n",
      " 0.58035719 0.69221384 0.67504547 0.62060995 0.60490463 0.6400576\n",
      " 0.75487792 0.66016415 0.70989813 0.66810738 0.74481366 0.57804852]\n",
      "Macro AUC: 0.6519101301456064\n",
      "MAP per class: [0.22509461 0.2817675  0.14038211 0.14526819 0.32312721 0.18350508\n",
      " 0.76949098 0.44605404 0.75715321 0.2857434  0.7617734  0.14945905\n",
      " 0.6019711  0.50926099 0.55313271 0.50419387 0.06440635 0.31867894\n",
      " 0.78490038 0.08599605 0.36376291 0.40816022 0.57727207 0.67840173\n",
      " 0.32988926 0.77708161 0.37621159 0.26795017 0.14310933 0.69010027]\n",
      "Macro MAP: 0.41677661047244047\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical + demo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = pd.concat([train.loc[:, \"1\":\"880\"], train.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, \"1\":\"880\"], test.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.5330 - auc_36: 0.7751 - val_loss: 0.4709 - val_auc_36: 0.8110\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4862 - auc_36: 0.8194 - val_loss: 0.4677 - val_auc_36: 0.8176\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4609 - auc_36: 0.8417 - val_loss: 0.4772 - val_auc_36: 0.8153\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4374 - auc_36: 0.8599 - val_loss: 0.4733 - val_auc_36: 0.8088\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4140 - auc_36: 0.8763 - val_loss: 0.4925 - val_auc_36: 0.8078\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3969 - auc_36: 0.8870 - val_loss: 0.4666 - val_auc_36: 0.8119\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3828 - auc_36: 0.8957 - val_loss: 0.4979 - val_auc_36: 0.8074\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3653 - auc_36: 0.9059 - val_loss: 0.4836 - val_auc_36: 0.8083\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3593 - auc_36: 0.9087 - val_loss: 0.4989 - val_auc_36: 0.8064\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3497 - auc_36: 0.9141 - val_loss: 0.4969 - val_auc_36: 0.8039\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3383 - auc_36: 0.9198 - val_loss: 0.5022 - val_auc_36: 0.8021\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3343 - auc_36: 0.9217 - val_loss: 0.5020 - val_auc_36: 0.8050\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3220 - auc_36: 0.9277 - val_loss: 0.5049 - val_auc_36: 0.8050\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3175 - auc_36: 0.9298 - val_loss: 0.5159 - val_auc_36: 0.8035\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3117 - auc_36: 0.9324 - val_loss: 0.5123 - val_auc_36: 0.8000\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3071 - auc_36: 0.9346 - val_loss: 0.5267 - val_auc_36: 0.7992\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3030 - auc_36: 0.9364 - val_loss: 0.5226 - val_auc_36: 0.8035\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2971 - auc_36: 0.9388 - val_loss: 0.5219 - val_auc_36: 0.8035\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2931 - auc_36: 0.9404 - val_loss: 0.5302 - val_auc_36: 0.8005\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2925 - auc_36: 0.9406 - val_loss: 0.5411 - val_auc_36: 0.8010\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2879 - auc_36: 0.9426 - val_loss: 0.5278 - val_auc_36: 0.7970\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2850 - auc_36: 0.9437 - val_loss: 0.5355 - val_auc_36: 0.7991\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2784 - auc_36: 0.9466 - val_loss: 0.5320 - val_auc_36: 0.7996\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2776 - auc_36: 0.9468 - val_loss: 0.5344 - val_auc_36: 0.7984\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2745 - auc_36: 0.9479 - val_loss: 0.5466 - val_auc_36: 0.7996\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2711 - auc_36: 0.9492 - val_loss: 0.5436 - val_auc_36: 0.8030\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2657 - auc_36: 0.9512 - val_loss: 0.5648 - val_auc_36: 0.7963\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2664 - auc_36: 0.9510 - val_loss: 0.5549 - val_auc_36: 0.7993\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2637 - auc_36: 0.9521 - val_loss: 0.5500 - val_auc_36: 0.7994\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2624 - auc_36: 0.9525 - val_loss: 0.5737 - val_auc_36: 0.7969\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2616 - auc_36: 0.9527 - val_loss: 0.5660 - val_auc_36: 0.7999\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2600 - auc_36: 0.9534 - val_loss: 0.5689 - val_auc_36: 0.7963\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2597 - auc_36: 0.9535 - val_loss: 0.5630 - val_auc_36: 0.8003\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2534 - auc_36: 0.9557 - val_loss: 0.5659 - val_auc_36: 0.7973\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2521 - auc_36: 0.9563 - val_loss: 0.5600 - val_auc_36: 0.7972\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2526 - auc_36: 0.9559 - val_loss: 0.5837 - val_auc_36: 0.7917\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2488 - auc_36: 0.9573 - val_loss: 0.5633 - val_auc_36: 0.8007\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2485 - auc_36: 0.9575 - val_loss: 0.5710 - val_auc_36: 0.7979\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2476 - auc_36: 0.9577 - val_loss: 0.5855 - val_auc_36: 0.7994\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2454 - auc_36: 0.9585 - val_loss: 0.5908 - val_auc_36: 0.7987\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2415 - auc_36: 0.9598 - val_loss: 0.5802 - val_auc_36: 0.7970\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2414 - auc_36: 0.9599 - val_loss: 0.5949 - val_auc_36: 0.7973\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2387 - auc_36: 0.9607 - val_loss: 0.5824 - val_auc_36: 0.8000\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2361 - auc_36: 0.9616 - val_loss: 0.5970 - val_auc_36: 0.7950\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2376 - auc_36: 0.9612 - val_loss: 0.5732 - val_auc_36: 0.8015\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2363 - auc_36: 0.9616 - val_loss: 0.5883 - val_auc_36: 0.7988\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2345 - auc_36: 0.9621 - val_loss: 0.6085 - val_auc_36: 0.7971\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2341 - auc_36: 0.9623 - val_loss: 0.5874 - val_auc_36: 0.7990\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2315 - auc_36: 0.9631 - val_loss: 0.5955 - val_auc_36: 0.7981\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2304 - auc_36: 0.9635 - val_loss: 0.5925 - val_auc_36: 0.7948\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2304 - auc_36: 0.9635 - val_loss: 0.5877 - val_auc_36: 0.7994\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2294 - auc_36: 0.9638 - val_loss: 0.6052 - val_auc_36: 0.7973\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2278 - auc_36: 0.9643 - val_loss: 0.6078 - val_auc_36: 0.7981\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2275 - auc_36: 0.9645 - val_loss: 0.6168 - val_auc_36: 0.7955\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2269 - auc_36: 0.9646 - val_loss: 0.6079 - val_auc_36: 0.7948\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2226 - auc_36: 0.9659 - val_loss: 0.6315 - val_auc_36: 0.7978\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2261 - auc_36: 0.9648 - val_loss: 0.6153 - val_auc_36: 0.7977\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2212 - auc_36: 0.9663 - val_loss: 0.6097 - val_auc_36: 0.7973\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2219 - auc_36: 0.9662 - val_loss: 0.6055 - val_auc_36: 0.7950\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2199 - auc_36: 0.9667 - val_loss: 0.6377 - val_auc_36: 0.7978\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2187 - auc_36: 0.9671 - val_loss: 0.5947 - val_auc_36: 0.7984\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2227 - auc_36: 0.9659 - val_loss: 0.6294 - val_auc_36: 0.7941\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2203 - auc_36: 0.9666 - val_loss: 0.6237 - val_auc_36: 0.7938\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2177 - auc_36: 0.9674 - val_loss: 0.6132 - val_auc_36: 0.7968\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2164 - auc_36: 0.9679 - val_loss: 0.6330 - val_auc_36: 0.7942\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2138 - auc_36: 0.9686 - val_loss: 0.6279 - val_auc_36: 0.7946\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2164 - auc_36: 0.9678 - val_loss: 0.6195 - val_auc_36: 0.7980\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2130 - auc_36: 0.9688 - val_loss: 0.6167 - val_auc_36: 0.7991\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2141 - auc_36: 0.9685 - val_loss: 0.6332 - val_auc_36: 0.7990\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2106 - auc_36: 0.9696 - val_loss: 0.6213 - val_auc_36: 0.7977\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2125 - auc_36: 0.9690 - val_loss: 0.6309 - val_auc_36: 0.7968\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2097 - auc_36: 0.9698 - val_loss: 0.6342 - val_auc_36: 0.7961\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2082 - auc_36: 0.9702 - val_loss: 0.6379 - val_auc_36: 0.7972\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2065 - auc_36: 0.9708 - val_loss: 0.6342 - val_auc_36: 0.7963\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2107 - auc_36: 0.9695 - val_loss: 0.6279 - val_auc_36: 0.7946\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2090 - auc_36: 0.9700 - val_loss: 0.6351 - val_auc_36: 0.7976\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2088 - auc_36: 0.9701 - val_loss: 0.6478 - val_auc_36: 0.7942\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2070 - auc_36: 0.9705 - val_loss: 0.6317 - val_auc_36: 0.7976\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2057 - auc_36: 0.9710 - val_loss: 0.6320 - val_auc_36: 0.8005\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2066 - auc_36: 0.9706 - val_loss: 0.6519 - val_auc_36: 0.7976\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2061 - auc_36: 0.9709 - val_loss: 0.6313 - val_auc_36: 0.7977\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2048 - auc_36: 0.9712 - val_loss: 0.6381 - val_auc_36: 0.7931\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2032 - auc_36: 0.9717 - val_loss: 0.6485 - val_auc_36: 0.7963\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2030 - auc_36: 0.9717 - val_loss: 0.6309 - val_auc_36: 0.7977\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2017 - auc_36: 0.9721 - val_loss: 0.6531 - val_auc_36: 0.7962\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2023 - auc_36: 0.9719 - val_loss: 0.6287 - val_auc_36: 0.7976\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2012 - auc_36: 0.9722 - val_loss: 0.6527 - val_auc_36: 0.7953\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2013 - auc_36: 0.9722 - val_loss: 0.6295 - val_auc_36: 0.7957\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2003 - auc_36: 0.9725 - val_loss: 0.6438 - val_auc_36: 0.7968\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2003 - auc_36: 0.9724 - val_loss: 0.6548 - val_auc_36: 0.7971\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1986 - auc_36: 0.9729 - val_loss: 0.6594 - val_auc_36: 0.7964\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1984 - auc_36: 0.9729 - val_loss: 0.6554 - val_auc_36: 0.7953\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1977 - auc_36: 0.9732 - val_loss: 0.6580 - val_auc_36: 0.7919\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1972 - auc_36: 0.9733 - val_loss: 0.6844 - val_auc_36: 0.7923\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1979 - auc_36: 0.9731 - val_loss: 0.6408 - val_auc_36: 0.7972\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1970 - auc_36: 0.9734 - val_loss: 0.6677 - val_auc_36: 0.7962\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1983 - auc_36: 0.9729 - val_loss: 0.6768 - val_auc_36: 0.7953\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1972 - auc_36: 0.9733 - val_loss: 0.6556 - val_auc_36: 0.7937\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1945 - auc_36: 0.9740 - val_loss: 0.6639 - val_auc_36: 0.7959\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1928 - auc_36: 0.9745 - val_loss: 0.6679 - val_auc_36: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aac4516a650>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train = pd.concat([train.loc[:, \"1\":\"880\"], train.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, \"1\":\"880\"], test.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.61176582 0.71074807 0.61222637 0.65264765 0.61240131 0.55547729\n",
      " 0.64726764 0.62459105 0.66115033 0.62496295 0.61138312 0.5224459\n",
      " 0.61179254 0.62175436 0.59435192 0.62720349 0.62614834 0.65641424\n",
      " 0.59627406 0.76073092 0.63761201 0.61857324 0.68114766 0.58555284\n",
      " 0.66119481 0.63235403 0.69404603 0.65149616 0.80719114 0.600281  ]\n",
      "Macro AUC: 0.6370395432093151\n",
      "MAP per class: [0.21162396 0.30607932 0.15676241 0.27597084 0.29053588 0.17884552\n",
      " 0.75018513 0.41032247 0.78196239 0.32356821 0.76006313 0.04553831\n",
      " 0.56523946 0.47459225 0.55951766 0.39955694 0.0775028  0.36777358\n",
      " 0.80493079 0.13803255 0.35826431 0.41042006 0.64280857 0.63275769\n",
      " 0.21213824 0.76160539 0.31305622 0.19634679 0.17973365 0.69978887]\n",
      "Macro MAP: 0.40951744682883023\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular +Demo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, 'molecular_weight': 'covalent_unit_count'], test.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.5169 - auc_37: 0.7885 - val_loss: 0.4610 - val_auc_37: 0.8112\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5080 - auc_37: 0.7975 - val_loss: 0.4718 - val_auc_37: 0.8123\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5065 - auc_37: 0.7990 - val_loss: 0.4765 - val_auc_37: 0.8121\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5059 - auc_37: 0.7996 - val_loss: 0.4651 - val_auc_37: 0.8112\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5050 - auc_37: 0.8006 - val_loss: 0.4802 - val_auc_37: 0.8123\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5031 - auc_37: 0.8024 - val_loss: 0.4624 - val_auc_37: 0.8109\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5034 - auc_37: 0.8020 - val_loss: 0.4720 - val_auc_37: 0.8112\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5020 - auc_37: 0.8034 - val_loss: 0.4755 - val_auc_37: 0.8096\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5027 - auc_37: 0.8029 - val_loss: 0.4713 - val_auc_37: 0.8112\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5020 - auc_37: 0.8036 - val_loss: 0.4855 - val_auc_37: 0.8121\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5021 - auc_37: 0.8033 - val_loss: 0.4837 - val_auc_37: 0.8120\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5011 - auc_37: 0.8043 - val_loss: 0.4613 - val_auc_37: 0.8131\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5015 - auc_37: 0.8039 - val_loss: 0.4798 - val_auc_37: 0.8110\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5005 - auc_37: 0.8048 - val_loss: 0.4583 - val_auc_37: 0.8096\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.5004 - auc_37: 0.8050 - val_loss: 0.4691 - val_auc_37: 0.8100\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4997 - auc_37: 0.8056 - val_loss: 0.4853 - val_auc_37: 0.8118\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4997 - auc_37: 0.8055 - val_loss: 0.4805 - val_auc_37: 0.8118\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4996 - auc_37: 0.8055 - val_loss: 0.4696 - val_auc_37: 0.8134\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4997 - auc_37: 0.8056 - val_loss: 0.4684 - val_auc_37: 0.8109\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.4992 - auc_37: 0.8060 - val_loss: 0.4774 - val_auc_37: 0.8098\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4984 - auc_37: 0.8066 - val_loss: 0.4683 - val_auc_37: 0.8084\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4981 - auc_37: 0.8070 - val_loss: 0.4888 - val_auc_37: 0.8109\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4982 - auc_37: 0.8070 - val_loss: 0.4666 - val_auc_37: 0.8103\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4976 - auc_37: 0.8075 - val_loss: 0.4653 - val_auc_37: 0.8127\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4986 - auc_37: 0.8065 - val_loss: 0.4803 - val_auc_37: 0.8107\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4973 - auc_37: 0.8076 - val_loss: 0.4831 - val_auc_37: 0.8091\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4973 - auc_37: 0.8077 - val_loss: 0.4724 - val_auc_37: 0.8095\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4972 - auc_37: 0.8077 - val_loss: 0.4735 - val_auc_37: 0.8112\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4971 - auc_37: 0.8079 - val_loss: 0.4714 - val_auc_37: 0.8095\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4958 - auc_37: 0.8090 - val_loss: 0.4796 - val_auc_37: 0.8113\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4959 - auc_37: 0.8091 - val_loss: 0.4800 - val_auc_37: 0.8100\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4971 - auc_37: 0.8078 - val_loss: 0.4626 - val_auc_37: 0.8102\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4954 - auc_37: 0.8094 - val_loss: 0.4731 - val_auc_37: 0.8090\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4967 - auc_37: 0.8083 - val_loss: 0.4792 - val_auc_37: 0.8101\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4958 - auc_37: 0.8089 - val_loss: 0.4765 - val_auc_37: 0.8090\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4952 - auc_37: 0.8096 - val_loss: 0.4726 - val_auc_37: 0.8081\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4958 - auc_37: 0.8090 - val_loss: 0.4756 - val_auc_37: 0.8092\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4959 - auc_37: 0.8090 - val_loss: 0.4783 - val_auc_37: 0.8087\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4953 - auc_37: 0.8096 - val_loss: 0.4671 - val_auc_37: 0.8090\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4948 - auc_37: 0.8098 - val_loss: 0.4731 - val_auc_37: 0.8087\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4946 - auc_37: 0.8102 - val_loss: 0.4853 - val_auc_37: 0.8093\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4950 - auc_37: 0.8099 - val_loss: 0.4770 - val_auc_37: 0.8085\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4945 - auc_37: 0.8103 - val_loss: 0.4725 - val_auc_37: 0.8101\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4950 - auc_37: 0.8099 - val_loss: 0.4695 - val_auc_37: 0.8092\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4947 - auc_37: 0.8102 - val_loss: 0.4774 - val_auc_37: 0.8104\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4937 - auc_37: 0.8111 - val_loss: 0.4784 - val_auc_37: 0.8100\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4939 - auc_37: 0.8109 - val_loss: 0.4785 - val_auc_37: 0.8089\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4941 - auc_37: 0.8106 - val_loss: 0.4736 - val_auc_37: 0.8084\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4939 - auc_37: 0.8107 - val_loss: 0.4737 - val_auc_37: 0.8085\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4939 - auc_37: 0.8109 - val_loss: 0.4774 - val_auc_37: 0.8106\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4937 - auc_37: 0.8111 - val_loss: 0.4749 - val_auc_37: 0.8090\n",
      "Epoch 52/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4942 - auc_37: 0.8105 - val_loss: 0.4685 - val_auc_37: 0.8114\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4934 - auc_37: 0.8113 - val_loss: 0.4674 - val_auc_37: 0.8113\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4933 - auc_37: 0.8114 - val_loss: 0.4759 - val_auc_37: 0.8083\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4937 - auc_37: 0.8112 - val_loss: 0.4768 - val_auc_37: 0.8094\n",
      "Epoch 56/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4930 - auc_37: 0.8117 - val_loss: 0.4734 - val_auc_37: 0.8090\n",
      "Epoch 57/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4930 - auc_37: 0.8116 - val_loss: 0.4814 - val_auc_37: 0.8103\n",
      "Epoch 58/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4933 - auc_37: 0.8115 - val_loss: 0.4822 - val_auc_37: 0.8093\n",
      "Epoch 59/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4922 - auc_37: 0.8124 - val_loss: 0.4802 - val_auc_37: 0.8086\n",
      "Epoch 60/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4932 - auc_37: 0.8115 - val_loss: 0.4818 - val_auc_37: 0.8100\n",
      "Epoch 61/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4929 - auc_37: 0.8119 - val_loss: 0.4815 - val_auc_37: 0.8087\n",
      "Epoch 62/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4929 - auc_37: 0.8118 - val_loss: 0.4852 - val_auc_37: 0.8081\n",
      "Epoch 63/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4927 - auc_37: 0.8120 - val_loss: 0.4800 - val_auc_37: 0.8100\n",
      "Epoch 64/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4929 - auc_37: 0.8118 - val_loss: 0.4835 - val_auc_37: 0.8093\n",
      "Epoch 65/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4935 - auc_37: 0.8113 - val_loss: 0.4801 - val_auc_37: 0.8093\n",
      "Epoch 66/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4924 - auc_37: 0.8122 - val_loss: 0.4758 - val_auc_37: 0.8092\n",
      "Epoch 67/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4926 - auc_37: 0.8123 - val_loss: 0.4787 - val_auc_37: 0.8095\n",
      "Epoch 68/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4923 - auc_37: 0.8123 - val_loss: 0.4758 - val_auc_37: 0.8077\n",
      "Epoch 69/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4924 - auc_37: 0.8125 - val_loss: 0.4809 - val_auc_37: 0.8083\n",
      "Epoch 70/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4925 - auc_37: 0.8124 - val_loss: 0.4807 - val_auc_37: 0.8093\n",
      "Epoch 71/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4918 - auc_37: 0.8129 - val_loss: 0.4833 - val_auc_37: 0.8077\n",
      "Epoch 72/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4930 - auc_37: 0.8119 - val_loss: 0.4784 - val_auc_37: 0.8082\n",
      "Epoch 73/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4921 - auc_37: 0.8126 - val_loss: 0.4838 - val_auc_37: 0.8097\n",
      "Epoch 74/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4922 - auc_37: 0.8126 - val_loss: 0.4762 - val_auc_37: 0.8076\n",
      "Epoch 75/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4919 - auc_37: 0.8128 - val_loss: 0.4781 - val_auc_37: 0.8108\n",
      "Epoch 76/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4926 - auc_37: 0.8123 - val_loss: 0.4815 - val_auc_37: 0.8100\n",
      "Epoch 77/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4911 - auc_37: 0.8135 - val_loss: 0.4805 - val_auc_37: 0.8099\n",
      "Epoch 78/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4919 - auc_37: 0.8128 - val_loss: 0.4770 - val_auc_37: 0.8100\n",
      "Epoch 79/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4918 - auc_37: 0.8130 - val_loss: 0.4885 - val_auc_37: 0.8084\n",
      "Epoch 80/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4922 - auc_37: 0.8126 - val_loss: 0.4859 - val_auc_37: 0.8074\n",
      "Epoch 81/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4925 - auc_37: 0.8124 - val_loss: 0.4887 - val_auc_37: 0.8082\n",
      "Epoch 82/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4924 - auc_37: 0.8123 - val_loss: 0.4803 - val_auc_37: 0.8084\n",
      "Epoch 83/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4920 - auc_37: 0.8127 - val_loss: 0.4882 - val_auc_37: 0.8066\n",
      "Epoch 84/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4916 - auc_37: 0.8131 - val_loss: 0.4825 - val_auc_37: 0.8065\n",
      "Epoch 85/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4907 - auc_37: 0.8140 - val_loss: 0.4835 - val_auc_37: 0.8071\n",
      "Epoch 86/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4907 - auc_37: 0.8139 - val_loss: 0.4848 - val_auc_37: 0.8096\n",
      "Epoch 87/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4925 - auc_37: 0.8123 - val_loss: 0.4810 - val_auc_37: 0.8114\n",
      "Epoch 88/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4918 - auc_37: 0.8130 - val_loss: 0.4824 - val_auc_37: 0.8094\n",
      "Epoch 89/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4918 - auc_37: 0.8130 - val_loss: 0.4811 - val_auc_37: 0.8097\n",
      "Epoch 90/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4908 - auc_37: 0.8139 - val_loss: 0.4858 - val_auc_37: 0.8084\n",
      "Epoch 91/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4918 - auc_37: 0.8131 - val_loss: 0.4872 - val_auc_37: 0.8086\n",
      "Epoch 92/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4915 - auc_37: 0.8135 - val_loss: 0.4838 - val_auc_37: 0.8076\n",
      "Epoch 93/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4910 - auc_37: 0.8136 - val_loss: 0.4788 - val_auc_37: 0.8094\n",
      "Epoch 94/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4918 - auc_37: 0.8129 - val_loss: 0.4855 - val_auc_37: 0.8104\n",
      "Epoch 95/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4906 - auc_37: 0.8141 - val_loss: 0.4857 - val_auc_37: 0.8088\n",
      "Epoch 96/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4907 - auc_37: 0.8140 - val_loss: 0.4835 - val_auc_37: 0.8067\n",
      "Epoch 97/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4917 - auc_37: 0.8132 - val_loss: 0.4821 - val_auc_37: 0.8086\n",
      "Epoch 98/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4908 - auc_37: 0.8139 - val_loss: 0.4880 - val_auc_37: 0.8094\n",
      "Epoch 99/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4919 - auc_37: 0.8131 - val_loss: 0.4794 - val_auc_37: 0.8094\n",
      "Epoch 100/100\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.4917 - auc_37: 0.8132 - val_loss: 0.4919 - val_auc_37: 0.8092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aad7aa3db10>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, 'molecular_weight': 'covalent_unit_count'], test.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.56854847 0.58027143 0.62767176 0.71029223 0.53529965 0.60679755\n",
      " 0.6307429  0.60187048 0.5987371  0.64310059 0.60932611 0.61200715\n",
      " 0.59157655 0.54930057 0.58495941 0.59357734 0.60615772 0.62598907\n",
      " 0.5701289  0.65280859 0.66945009 0.59202237 0.57650766 0.57575246\n",
      " 0.67053313 0.62571617 0.67188612 0.6562626  0.70680664 0.53928953]\n",
      "Macro AUC: 0.6127796778998363\n",
      "MAP per class: [0.16660486 0.17594247 0.13966269 0.09241311 0.22258885 0.16756785\n",
      " 0.74386568 0.30750478 0.69978594 0.24195663 0.77044123 0.06667893\n",
      " 0.53325404 0.37086195 0.49217237 0.38900268 0.12202248 0.30604296\n",
      " 0.78200562 0.14343922 0.28276766 0.37347775 0.5411324  0.6275769\n",
      " 0.20097534 0.73528517 0.30178382 0.23855536 0.0874901  0.66330018]\n",
      "Macro MAP: 0.36620530073298707\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular +bio"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, \"A0A068JFB7\":\"W7JWW5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, 'molecular_weight': 'covalent_unit_count'], test.loc[:, \"A0A068JFB7\":\"W7JWW5\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 0.5494 - auc_38: 0.7644 - val_loss: 0.4610 - val_auc_38: 0.8169\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4460 - auc_38: 0.8539 - val_loss: 0.4630 - val_auc_38: 0.8193\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3888 - auc_38: 0.8929 - val_loss: 0.4704 - val_auc_38: 0.8189\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3546 - auc_38: 0.9123 - val_loss: 0.4677 - val_auc_38: 0.8159\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3300 - auc_38: 0.9248 - val_loss: 0.4698 - val_auc_38: 0.8185\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3134 - auc_38: 0.9327 - val_loss: 0.4769 - val_auc_38: 0.8130\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3001 - auc_38: 0.9386 - val_loss: 0.4937 - val_auc_38: 0.8104\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2884 - auc_38: 0.9435 - val_loss: 0.4890 - val_auc_38: 0.8071\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2802 - auc_38: 0.9468 - val_loss: 0.5089 - val_auc_38: 0.8078\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.2727 - auc_38: 0.9497 - val_loss: 0.5092 - val_auc_38: 0.8066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aad7a86ed50>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, \"A0A068JFB7\":\"W7JWW5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, 'molecular_weight': 'covalent_unit_count'], test.loc[:, \"A0A068JFB7\":\"W7JWW5\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.64576322 0.69688131 0.6906005  0.85999456 0.65738683 0.64319944\n",
      " 0.6614555  0.67547978 0.63778942 0.60708791 0.63085138 0.89745086\n",
      " 0.60397769 0.65896801 0.69614755 0.63560138 0.65921877 0.65486514\n",
      " 0.55253573 0.67002489 0.70516015 0.65190809 0.60281102 0.61448574\n",
      " 0.79458489 0.66529535 0.68134885 0.67373359 0.69192614 0.59587449]\n",
      "Macro AUC: 0.6704136069292725\n",
      "MAP per class: [0.23425484 0.28754954 0.16437083 0.26416267 0.34728397 0.19575778\n",
      " 0.76486228 0.44771852 0.7673123  0.2572883  0.79037871 0.28206005\n",
      " 0.61519011 0.552457   0.60918546 0.47538559 0.11312156 0.38393146\n",
      " 0.77724265 0.09699255 0.37002467 0.45221531 0.61673068 0.6948101\n",
      " 0.34954385 0.79262674 0.41494128 0.32015828 0.29088021 0.71855857]\n",
      "Macro MAP: 0.4482331954878236\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical molecular"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, 'molecular_weight': 'covalent_unit_count'], test.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.5220 - auc_39: 0.7854 - val_loss: 0.4750 - val_auc_39: 0.8153\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4652 - auc_39: 0.8379 - val_loss: 0.4652 - val_auc_39: 0.8177\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4263 - auc_39: 0.8684 - val_loss: 0.4669 - val_auc_39: 0.8145\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3905 - auc_39: 0.8919 - val_loss: 0.4719 - val_auc_39: 0.8095\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3636 - auc_39: 0.9076 - val_loss: 0.4853 - val_auc_39: 0.8102\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3436 - auc_39: 0.9181 - val_loss: 0.5027 - val_auc_39: 0.8056\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3268 - auc_39: 0.9263 - val_loss: 0.5362 - val_auc_39: 0.7987\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3155 - auc_39: 0.9316 - val_loss: 0.5212 - val_auc_39: 0.7971\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3035 - auc_39: 0.9369 - val_loss: 0.5392 - val_auc_39: 0.8017\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2911 - auc_39: 0.9422 - val_loss: 0.5458 - val_auc_39: 0.7970\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2850 - auc_39: 0.9445 - val_loss: 0.5705 - val_auc_39: 0.7929\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2810 - auc_39: 0.9462 - val_loss: 0.5274 - val_auc_39: 0.7973\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2724 - auc_39: 0.9495 - val_loss: 0.5508 - val_auc_39: 0.7927\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2660 - auc_39: 0.9519 - val_loss: 0.5744 - val_auc_39: 0.7946\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2641 - auc_39: 0.9525 - val_loss: 0.5589 - val_auc_39: 0.7941\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2578 - auc_39: 0.9547 - val_loss: 0.5769 - val_auc_39: 0.7939\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2555 - auc_39: 0.9555 - val_loss: 0.5703 - val_auc_39: 0.7948\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2513 - auc_39: 0.9569 - val_loss: 0.5908 - val_auc_39: 0.7920\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2456 - auc_39: 0.9588 - val_loss: 0.5621 - val_auc_39: 0.7940\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2460 - auc_39: 0.9586 - val_loss: 0.5961 - val_auc_39: 0.7910\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2418 - auc_39: 0.9600 - val_loss: 0.6019 - val_auc_39: 0.7922\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2380 - auc_39: 0.9613 - val_loss: 0.5882 - val_auc_39: 0.7949\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2370 - auc_39: 0.9616 - val_loss: 0.5802 - val_auc_39: 0.7948\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2338 - auc_39: 0.9625 - val_loss: 0.6055 - val_auc_39: 0.7892\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2336 - auc_39: 0.9626 - val_loss: 0.5992 - val_auc_39: 0.7887\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2294 - auc_39: 0.9639 - val_loss: 0.5977 - val_auc_39: 0.7940\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2288 - auc_39: 0.9640 - val_loss: 0.5996 - val_auc_39: 0.7923\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2261 - auc_39: 0.9648 - val_loss: 0.5994 - val_auc_39: 0.7939\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2243 - auc_39: 0.9654 - val_loss: 0.5931 - val_auc_39: 0.7892\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2249 - auc_39: 0.9652 - val_loss: 0.5935 - val_auc_39: 0.7951\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2219 - auc_39: 0.9661 - val_loss: 0.5911 - val_auc_39: 0.7929\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2219 - auc_39: 0.9661 - val_loss: 0.5887 - val_auc_39: 0.7941\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2197 - auc_39: 0.9667 - val_loss: 0.6019 - val_auc_39: 0.7884\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2185 - auc_39: 0.9670 - val_loss: 0.6177 - val_auc_39: 0.7910\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2175 - auc_39: 0.9673 - val_loss: 0.6206 - val_auc_39: 0.7941\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2170 - auc_39: 0.9675 - val_loss: 0.6112 - val_auc_39: 0.7919\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2155 - auc_39: 0.9678 - val_loss: 0.6167 - val_auc_39: 0.7932\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2147 - auc_39: 0.9680 - val_loss: 0.6301 - val_auc_39: 0.7867\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2121 - auc_39: 0.9688 - val_loss: 0.6310 - val_auc_39: 0.7944\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2123 - auc_39: 0.9687 - val_loss: 0.6071 - val_auc_39: 0.7914\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2112 - auc_39: 0.9690 - val_loss: 0.6141 - val_auc_39: 0.7895\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2112 - auc_39: 0.9690 - val_loss: 0.6371 - val_auc_39: 0.7900\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2073 - auc_39: 0.9702 - val_loss: 0.6279 - val_auc_39: 0.7882\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2095 - auc_39: 0.9695 - val_loss: 0.6217 - val_auc_39: 0.7911\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2079 - auc_39: 0.9699 - val_loss: 0.6521 - val_auc_39: 0.7897\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2072 - auc_39: 0.9700 - val_loss: 0.6226 - val_auc_39: 0.7912\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2071 - auc_39: 0.9701 - val_loss: 0.6196 - val_auc_39: 0.7935\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2063 - auc_39: 0.9702 - val_loss: 0.6226 - val_auc_39: 0.7888\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2042 - auc_39: 0.9708 - val_loss: 0.6289 - val_auc_39: 0.7934\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2042 - auc_39: 0.9708 - val_loss: 0.6404 - val_auc_39: 0.7882\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2038 - auc_39: 0.9710 - val_loss: 0.6330 - val_auc_39: 0.7904\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2044 - auc_39: 0.9706 - val_loss: 0.6208 - val_auc_39: 0.7957\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2029 - auc_39: 0.9710 - val_loss: 0.6603 - val_auc_39: 0.7916\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2035 - auc_39: 0.9709 - val_loss: 0.6370 - val_auc_39: 0.7920\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2022 - auc_39: 0.9713 - val_loss: 0.6564 - val_auc_39: 0.7895\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2021 - auc_39: 0.9713 - val_loss: 0.6378 - val_auc_39: 0.7912\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2005 - auc_39: 0.9717 - val_loss: 0.6561 - val_auc_39: 0.7899\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2011 - auc_39: 0.9716 - val_loss: 0.6238 - val_auc_39: 0.7886\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2006 - auc_39: 0.9717 - val_loss: 0.6547 - val_auc_39: 0.7888\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2012 - auc_39: 0.9714 - val_loss: 0.6337 - val_auc_39: 0.7906\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2000 - auc_39: 0.9718 - val_loss: 0.6627 - val_auc_39: 0.7893\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1977 - auc_39: 0.9725 - val_loss: 0.6547 - val_auc_39: 0.7857\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1986 - auc_39: 0.9722 - val_loss: 0.6541 - val_auc_39: 0.7864\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1976 - auc_39: 0.9724 - val_loss: 0.6488 - val_auc_39: 0.7892\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1976 - auc_39: 0.9724 - val_loss: 0.6375 - val_auc_39: 0.7874\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1969 - auc_39: 0.9726 - val_loss: 0.6433 - val_auc_39: 0.7913\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1969 - auc_39: 0.9725 - val_loss: 0.6407 - val_auc_39: 0.7902\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1961 - auc_39: 0.9728 - val_loss: 0.6494 - val_auc_39: 0.7919\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1953 - auc_39: 0.9730 - val_loss: 0.6710 - val_auc_39: 0.7913\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1944 - auc_39: 0.9732 - val_loss: 0.6474 - val_auc_39: 0.7882\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1956 - auc_39: 0.9729 - val_loss: 0.6613 - val_auc_39: 0.7889\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1949 - auc_39: 0.9730 - val_loss: 0.6629 - val_auc_39: 0.7863\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1946 - auc_39: 0.9730 - val_loss: 0.6627 - val_auc_39: 0.7882\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1939 - auc_39: 0.9733 - val_loss: 0.6816 - val_auc_39: 0.7860\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1947 - auc_39: 0.9731 - val_loss: 0.6436 - val_auc_39: 0.7905\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1935 - auc_39: 0.9734 - val_loss: 0.6519 - val_auc_39: 0.7884\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1946 - auc_39: 0.9731 - val_loss: 0.6621 - val_auc_39: 0.7890\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1922 - auc_39: 0.9737 - val_loss: 0.6580 - val_auc_39: 0.7843\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1925 - auc_39: 0.9736 - val_loss: 0.6583 - val_auc_39: 0.7869\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1920 - auc_39: 0.9736 - val_loss: 0.6696 - val_auc_39: 0.7853\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1924 - auc_39: 0.9736 - val_loss: 0.6781 - val_auc_39: 0.7836\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1923 - auc_39: 0.9736 - val_loss: 0.6539 - val_auc_39: 0.7858\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1910 - auc_39: 0.9738 - val_loss: 0.6782 - val_auc_39: 0.7870\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1902 - auc_39: 0.9741 - val_loss: 0.6600 - val_auc_39: 0.7855\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1920 - auc_39: 0.9737 - val_loss: 0.6499 - val_auc_39: 0.7907\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1908 - auc_39: 0.9739 - val_loss: 0.6474 - val_auc_39: 0.7875\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1901 - auc_39: 0.9742 - val_loss: 0.6593 - val_auc_39: 0.7874\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1914 - auc_39: 0.9738 - val_loss: 0.6735 - val_auc_39: 0.7839\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1901 - auc_39: 0.9742 - val_loss: 0.6583 - val_auc_39: 0.7871\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1902 - auc_39: 0.9742 - val_loss: 0.6495 - val_auc_39: 0.7881\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1894 - auc_39: 0.9743 - val_loss: 0.6602 - val_auc_39: 0.7882\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1881 - auc_39: 0.9746 - val_loss: 0.6542 - val_auc_39: 0.7931\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1891 - auc_39: 0.9743 - val_loss: 0.6622 - val_auc_39: 0.7864\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1893 - auc_39: 0.9743 - val_loss: 0.6844 - val_auc_39: 0.7871\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1893 - auc_39: 0.9743 - val_loss: 0.6744 - val_auc_39: 0.7894\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1887 - auc_39: 0.9744 - val_loss: 0.6566 - val_auc_39: 0.7884\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1871 - auc_39: 0.9748 - val_loss: 0.6742 - val_auc_39: 0.7904\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1884 - auc_39: 0.9745 - val_loss: 0.6623 - val_auc_39: 0.7877\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1879 - auc_39: 0.9745 - val_loss: 0.6596 - val_auc_39: 0.7889\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1882 - auc_39: 0.9745 - val_loss: 0.6665 - val_auc_39: 0.7861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aad7bb50110>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, 'molecular_weight': 'covalent_unit_count'], test.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.62565682 0.64659983 0.59384459 0.69283991 0.62908583 0.52185679\n",
      " 0.6099789  0.59094454 0.60404045 0.66428587 0.53696149 0.53962676\n",
      " 0.58172741 0.61735562 0.59326656 0.62373943 0.62767649 0.59986716\n",
      " 0.54844941 0.74535394 0.62508563 0.58971096 0.64930534 0.53810072\n",
      " 0.67042581 0.5893236  0.65629404 0.66375095 0.74055715 0.60228853]\n",
      "Macro AUC: 0.6172666851827171\n",
      "MAP per class: [0.23759834 0.28603507 0.16864321 0.34492231 0.31405932 0.17849608\n",
      " 0.71682892 0.39611927 0.73564136 0.4037683  0.71615566 0.06777573\n",
      " 0.55597957 0.46735855 0.55957451 0.39783161 0.08240324 0.33366923\n",
      " 0.7653427  0.14798551 0.35766111 0.39880414 0.6135968  0.59732081\n",
      " 0.2249313  0.73758086 0.29778598 0.2327901  0.18753015 0.69373133]\n",
      "Macro MAP: 0.4072640359847588\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical Bio"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = pd.concat([train.loc[:, \"A0A068JFB7\":\"W7JWW5\"], train.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, \"A0A068JFB7\":\"W7JWW5\"], test.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.4997 - auc_40: 0.8066 - val_loss: 0.4783 - val_auc_40: 0.8166\n",
      "Epoch 2/20\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.4299 - auc_40: 0.8645 - val_loss: 0.4907 - val_auc_40: 0.8143\n",
      "Epoch 3/20\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.3880 - auc_40: 0.8915 - val_loss: 0.4716 - val_auc_40: 0.8138\n",
      "Epoch 4/20\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.3603 - auc_40: 0.9080 - val_loss: 0.4606 - val_auc_40: 0.8186\n",
      "Epoch 5/20\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.3436 - auc_40: 0.9170 - val_loss: 0.4634 - val_auc_40: 0.8170\n",
      "Epoch 6/20\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.3256 - auc_40: 0.9260 - val_loss: 0.4843 - val_auc_40: 0.8112\n",
      "Epoch 7/20\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.3140 - auc_40: 0.9315 - val_loss: 0.4798 - val_auc_40: 0.8052\n",
      "Epoch 8/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.3064 - auc_40: 0.9348 - val_loss: 0.5019 - val_auc_40: 0.8037\n",
      "Epoch 9/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2983 - auc_40: 0.9385 - val_loss: 0.4882 - val_auc_40: 0.8083\n",
      "Epoch 10/20\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.2924 - auc_40: 0.9410 - val_loss: 0.4833 - val_auc_40: 0.8097\n",
      "Epoch 11/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2839 - auc_40: 0.9446 - val_loss: 0.4935 - val_auc_40: 0.8015\n",
      "Epoch 12/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2800 - auc_40: 0.9459 - val_loss: 0.5310 - val_auc_40: 0.7988\n",
      "Epoch 13/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2750 - auc_40: 0.9483 - val_loss: 0.4961 - val_auc_40: 0.7964\n",
      "Epoch 14/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2739 - auc_40: 0.9486 - val_loss: 0.4945 - val_auc_40: 0.8067\n",
      "Epoch 15/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2678 - auc_40: 0.9508 - val_loss: 0.5073 - val_auc_40: 0.8037\n",
      "Epoch 16/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2660 - auc_40: 0.9514 - val_loss: 0.5056 - val_auc_40: 0.8035\n",
      "Epoch 17/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2626 - auc_40: 0.9526 - val_loss: 0.5007 - val_auc_40: 0.8038\n",
      "Epoch 18/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2583 - auc_40: 0.9542 - val_loss: 0.4925 - val_auc_40: 0.8085\n",
      "Epoch 19/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2600 - auc_40: 0.9536 - val_loss: 0.5117 - val_auc_40: 0.7986\n",
      "Epoch 20/20\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.2548 - auc_40: 0.9553 - val_loss: 0.5057 - val_auc_40: 0.8061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aad7acec5d0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train = pd.concat([train.loc[:, \"A0A068JFB7\":\"W7JWW5\"], train.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, \"A0A068JFB7\":\"W7JWW5\"], test.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.66167219 0.74235851 0.69944049 0.6941017  0.62827468 0.59651182\n",
      " 0.68453914 0.69391922 0.67878052 0.68504838 0.63223676 0.73880881\n",
      " 0.6358225  0.67583133 0.64430283 0.60751049 0.73764421 0.64821933\n",
      " 0.57036599 0.73036823 0.7060814  0.62324007 0.68044221 0.63080996\n",
      " 0.7707363  0.68307727 0.74245174 0.71161277 0.75283663 0.62501171]\n",
      "Macro AUC: 0.6770685733657058\n",
      "MAP per class: [0.34965871 0.3328716  0.22410298 0.17958207 0.31495072 0.19092548\n",
      " 0.80695245 0.53477631 0.79376008 0.35139521 0.7877715  0.15229497\n",
      " 0.64475231 0.57498375 0.58459033 0.41680021 0.15729024 0.3732578\n",
      " 0.8086243  0.17607678 0.41294213 0.44638212 0.67177663 0.6892785\n",
      " 0.33167571 0.8163479  0.40461377 0.2683183  0.21949049 0.74983642]\n",
      "Macro MAP: 0.45886932571968375\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical + Molecular + Demographic"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = pd.concat([train.loc[:, \"molecular_weight\":\"880\"], train.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, \"molecular_weight\":\"880\"], test.loc[:, \"sex_M\":\"age_group_5\"]],  axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5213 - auc_41: 0.7861 - val_loss: 0.4709 - val_auc_41: 0.8148\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4765 - auc_41: 0.8281 - val_loss: 0.4755 - val_auc_41: 0.8157\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4497 - auc_41: 0.8502 - val_loss: 0.4692 - val_auc_41: 0.8117\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4250 - auc_41: 0.8680 - val_loss: 0.4702 - val_auc_41: 0.8090\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4047 - auc_41: 0.8817 - val_loss: 0.4619 - val_auc_41: 0.8147\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3874 - auc_41: 0.8926 - val_loss: 0.4976 - val_auc_41: 0.8078\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3762 - auc_41: 0.8991 - val_loss: 0.4937 - val_auc_41: 0.7998\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3622 - auc_41: 0.9067 - val_loss: 0.4814 - val_auc_41: 0.8052\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3512 - auc_41: 0.9128 - val_loss: 0.4845 - val_auc_41: 0.8018\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3434 - auc_41: 0.9169 - val_loss: 0.5223 - val_auc_41: 0.7942\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3373 - auc_41: 0.9200 - val_loss: 0.5189 - val_auc_41: 0.7981\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3286 - auc_41: 0.9243 - val_loss: 0.5076 - val_auc_41: 0.8065\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3217 - auc_41: 0.9277 - val_loss: 0.5153 - val_auc_41: 0.8035\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3183 - auc_41: 0.9291 - val_loss: 0.5075 - val_auc_41: 0.8018\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3127 - auc_41: 0.9320 - val_loss: 0.5180 - val_auc_41: 0.8012\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3020 - auc_41: 0.9364 - val_loss: 0.5226 - val_auc_41: 0.7942\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2997 - auc_41: 0.9375 - val_loss: 0.5168 - val_auc_41: 0.7949\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2949 - auc_41: 0.9395 - val_loss: 0.5397 - val_auc_41: 0.7949\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2911 - auc_41: 0.9412 - val_loss: 0.5478 - val_auc_41: 0.7959\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2876 - auc_41: 0.9427 - val_loss: 0.5312 - val_auc_41: 0.7929\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2838 - auc_41: 0.9440 - val_loss: 0.5505 - val_auc_41: 0.7943\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2819 - auc_41: 0.9450 - val_loss: 0.5306 - val_auc_41: 0.7969\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2791 - auc_41: 0.9461 - val_loss: 0.5425 - val_auc_41: 0.7929\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2765 - auc_41: 0.9471 - val_loss: 0.5451 - val_auc_41: 0.7967\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2732 - auc_41: 0.9484 - val_loss: 0.5394 - val_auc_41: 0.7967\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2705 - auc_41: 0.9495 - val_loss: 0.5415 - val_auc_41: 0.7914\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2671 - auc_41: 0.9507 - val_loss: 0.5379 - val_auc_41: 0.7959\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2661 - auc_41: 0.9512 - val_loss: 0.5583 - val_auc_41: 0.7954\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2628 - auc_41: 0.9524 - val_loss: 0.5638 - val_auc_41: 0.7934\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2606 - auc_41: 0.9532 - val_loss: 0.5638 - val_auc_41: 0.7946\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2582 - auc_41: 0.9539 - val_loss: 0.5618 - val_auc_41: 0.7917\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2559 - auc_41: 0.9549 - val_loss: 0.5609 - val_auc_41: 0.7881\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2542 - auc_41: 0.9555 - val_loss: 0.5687 - val_auc_41: 0.7915\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2543 - auc_41: 0.9554 - val_loss: 0.5600 - val_auc_41: 0.7909\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2494 - auc_41: 0.9571 - val_loss: 0.5891 - val_auc_41: 0.7933\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2468 - auc_41: 0.9581 - val_loss: 0.5730 - val_auc_41: 0.7915\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2465 - auc_41: 0.9583 - val_loss: 0.5860 - val_auc_41: 0.7930\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2439 - auc_41: 0.9591 - val_loss: 0.5812 - val_auc_41: 0.7902\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2449 - auc_41: 0.9587 - val_loss: 0.5745 - val_auc_41: 0.7896\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2432 - auc_41: 0.9594 - val_loss: 0.5847 - val_auc_41: 0.7881\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2422 - auc_41: 0.9597 - val_loss: 0.5670 - val_auc_41: 0.7928\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2395 - auc_41: 0.9605 - val_loss: 0.5833 - val_auc_41: 0.7906\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2364 - auc_41: 0.9616 - val_loss: 0.6037 - val_auc_41: 0.7888\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2354 - auc_41: 0.9619 - val_loss: 0.5730 - val_auc_41: 0.7918\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2345 - auc_41: 0.9622 - val_loss: 0.5812 - val_auc_41: 0.7900\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2362 - auc_41: 0.9616 - val_loss: 0.6017 - val_auc_41: 0.7946\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2354 - auc_41: 0.9618 - val_loss: 0.5842 - val_auc_41: 0.7926\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2361 - auc_41: 0.9616 - val_loss: 0.5895 - val_auc_41: 0.7931\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2301 - auc_41: 0.9636 - val_loss: 0.5705 - val_auc_41: 0.7949\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2292 - auc_41: 0.9639 - val_loss: 0.5706 - val_auc_41: 0.7960\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2292 - auc_41: 0.9638 - val_loss: 0.5996 - val_auc_41: 0.7952\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2257 - auc_41: 0.9650 - val_loss: 0.5773 - val_auc_41: 0.7933\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2228 - auc_41: 0.9659 - val_loss: 0.6042 - val_auc_41: 0.7914\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2237 - auc_41: 0.9656 - val_loss: 0.5965 - val_auc_41: 0.7912\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2246 - auc_41: 0.9652 - val_loss: 0.5809 - val_auc_41: 0.7927\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2246 - auc_41: 0.9653 - val_loss: 0.6101 - val_auc_41: 0.7936\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2213 - auc_41: 0.9663 - val_loss: 0.5885 - val_auc_41: 0.7916\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2210 - auc_41: 0.9664 - val_loss: 0.6150 - val_auc_41: 0.7900\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2212 - auc_41: 0.9664 - val_loss: 0.6050 - val_auc_41: 0.7852\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2202 - auc_41: 0.9667 - val_loss: 0.6030 - val_auc_41: 0.7886\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2187 - auc_41: 0.9672 - val_loss: 0.5996 - val_auc_41: 0.7923\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2175 - auc_41: 0.9674 - val_loss: 0.5808 - val_auc_41: 0.7954\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2187 - auc_41: 0.9671 - val_loss: 0.6193 - val_auc_41: 0.7931\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2162 - auc_41: 0.9678 - val_loss: 0.6053 - val_auc_41: 0.7924\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2171 - auc_41: 0.9676 - val_loss: 0.5993 - val_auc_41: 0.7919\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2136 - auc_41: 0.9686 - val_loss: 0.5937 - val_auc_41: 0.7897\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2152 - auc_41: 0.9682 - val_loss: 0.6106 - val_auc_41: 0.7882\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2119 - auc_41: 0.9691 - val_loss: 0.6237 - val_auc_41: 0.7910\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2147 - auc_41: 0.9683 - val_loss: 0.6033 - val_auc_41: 0.7919\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2130 - auc_41: 0.9688 - val_loss: 0.6080 - val_auc_41: 0.7897\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2101 - auc_41: 0.9697 - val_loss: 0.6140 - val_auc_41: 0.7953\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2160 - auc_41: 0.9679 - val_loss: 0.5976 - val_auc_41: 0.7939\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2111 - auc_41: 0.9694 - val_loss: 0.6243 - val_auc_41: 0.7900\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2084 - auc_41: 0.9701 - val_loss: 0.6102 - val_auc_41: 0.7934\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2100 - auc_41: 0.9697 - val_loss: 0.6114 - val_auc_41: 0.7959\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2089 - auc_41: 0.9701 - val_loss: 0.6097 - val_auc_41: 0.7920\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2090 - auc_41: 0.9700 - val_loss: 0.6161 - val_auc_41: 0.7916\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2069 - auc_41: 0.9706 - val_loss: 0.6164 - val_auc_41: 0.7935\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2049 - auc_41: 0.9712 - val_loss: 0.6094 - val_auc_41: 0.7959\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2039 - auc_41: 0.9715 - val_loss: 0.6070 - val_auc_41: 0.7908\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2050 - auc_41: 0.9711 - val_loss: 0.6273 - val_auc_41: 0.7919\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2042 - auc_41: 0.9714 - val_loss: 0.6221 - val_auc_41: 0.7882\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2030 - auc_41: 0.9717 - val_loss: 0.6170 - val_auc_41: 0.7915\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2020 - auc_41: 0.9720 - val_loss: 0.6236 - val_auc_41: 0.7912\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2038 - auc_41: 0.9715 - val_loss: 0.6360 - val_auc_41: 0.7919\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2010 - auc_41: 0.9723 - val_loss: 0.6334 - val_auc_41: 0.7952\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2015 - auc_41: 0.9722 - val_loss: 0.6363 - val_auc_41: 0.7903\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2013 - auc_41: 0.9722 - val_loss: 0.6096 - val_auc_41: 0.7957\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2008 - auc_41: 0.9724 - val_loss: 0.6111 - val_auc_41: 0.7920\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2018 - auc_41: 0.9720 - val_loss: 0.6275 - val_auc_41: 0.7926\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2014 - auc_41: 0.9721 - val_loss: 0.6227 - val_auc_41: 0.7949\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1988 - auc_41: 0.9729 - val_loss: 0.6474 - val_auc_41: 0.7933\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1995 - auc_41: 0.9727 - val_loss: 0.6247 - val_auc_41: 0.7970\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2006 - auc_41: 0.9724 - val_loss: 0.6267 - val_auc_41: 0.7950\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1983 - auc_41: 0.9730 - val_loss: 0.6367 - val_auc_41: 0.7964\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1965 - auc_41: 0.9735 - val_loss: 0.6237 - val_auc_41: 0.7937\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1977 - auc_41: 0.9731 - val_loss: 0.6234 - val_auc_41: 0.7962\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1968 - auc_41: 0.9734 - val_loss: 0.6140 - val_auc_41: 0.7959\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.1963 - auc_41: 0.9735 - val_loss: 0.6354 - val_auc_41: 0.7952\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1972 - auc_41: 0.9733 - val_loss: 0.6341 - val_auc_41: 0.7966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aad7b23c550>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train = pd.concat([train.loc[:, \"molecular_weight\":\"880\"], train.loc[:, \"sex_M\":\"age_group_5\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([test.loc[:, \"molecular_weight\":\"880\"], test.loc[:, \"sex_M\":\"age_group_5\"]],  axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.62742373 0.7185768  0.59226554 0.69969606 0.60794139 0.53641393\n",
      " 0.62021691 0.62923824 0.64750385 0.63952123 0.58316787 0.54031368\n",
      " 0.62051253 0.61417508 0.59854543 0.62965003 0.5987751  0.63358741\n",
      " 0.5884142  0.76193249 0.64370443 0.61182568 0.64729106 0.57996954\n",
      " 0.61555583 0.62161237 0.70368822 0.68211325 0.82005805 0.60495034]\n",
      "Macro AUC: 0.6339546753030241\n",
      "MAP per class: [0.21913165 0.33744354 0.15514709 0.32442679 0.30240833 0.17858903\n",
      " 0.74291238 0.42157251 0.77146966 0.3313818  0.75811738 0.04764701\n",
      " 0.58255393 0.49870485 0.54988652 0.4166016  0.0731778  0.33465879\n",
      " 0.79947518 0.15026189 0.38951612 0.43196672 0.63528234 0.64598429\n",
      " 0.20132159 0.7588811  0.32758915 0.22398136 0.18148521 0.71950718]\n",
      "Macro MAP: 0.41703609319494533\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bio + Molecular + Demographic"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = train.loc[:, \"sex_M\":\"covalent_unit_count\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, \"sex_M\":\"covalent_unit_count\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 0.5601 - auc_8: 0.7550 - val_loss: 0.4698 - val_auc_8: 0.8118\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4893 - auc_8: 0.8165 - val_loss: 0.4591 - val_auc_8: 0.8170\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4606 - auc_8: 0.8412 - val_loss: 0.4556 - val_auc_8: 0.8157\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4345 - auc_8: 0.8612 - val_loss: 0.4502 - val_auc_8: 0.8191\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4124 - auc_8: 0.8761 - val_loss: 0.4570 - val_auc_8: 0.8205\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3982 - auc_8: 0.8851 - val_loss: 0.4483 - val_auc_8: 0.8212\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3891 - auc_8: 0.8912 - val_loss: 0.4519 - val_auc_8: 0.8207\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3793 - auc_8: 0.8970 - val_loss: 0.4539 - val_auc_8: 0.8214\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3705 - auc_8: 0.9019 - val_loss: 0.4578 - val_auc_8: 0.8158\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.3638 - auc_8: 0.9058 - val_loss: 0.4585 - val_auc_8: 0.8198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aac3a171f90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train = train.loc[:, \"sex_M\":\"covalent_unit_count\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, \"sex_M\":\"covalent_unit_count\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.9))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.63138096 0.73950154 0.69945591 0.8325665  0.6690503  0.71306832\n",
      " 0.67107661 0.71038237 0.66725962 0.63466919 0.63750301 0.87647409\n",
      " 0.62380101 0.67936931 0.70258772 0.68411977 0.67270807 0.65546371\n",
      " 0.57652959 0.77569506 0.71604581 0.67603372 0.62087521 0.66085233\n",
      " 0.77947922 0.68214413 0.72965973 0.73265173 0.65619346 0.60765128]\n",
      "Macro AUC: 0.690474976141581\n",
      "MAP per class: [0.22610889 0.31867924 0.18946795 0.22218603 0.34715935 0.23931166\n",
      " 0.79692812 0.51016638 0.78927788 0.27329514 0.79884125 0.17553393\n",
      " 0.62280393 0.5730576  0.63507444 0.49915965 0.10190647 0.35613203\n",
      " 0.79567534 0.17471724 0.38408062 0.48933294 0.6129043  0.72653872\n",
      " 0.33628175 0.80702567 0.46490499 0.36284227 0.18345973 0.73682716]\n",
      "Macro MAP: 0.4583226886628529\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bio chemical demo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = pd.concat([ train.loc[:, \"sex_M\":\"W7JWW5\"], train.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([ test.loc[:, \"sex_M\":\"W7JWW5\"], test.loc[:, \"1\":\"880\"]],  axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 0.5257 - auc_43: 0.7832 - val_loss: 0.4629 - val_auc_43: 0.8174\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4568 - auc_43: 0.8448 - val_loss: 0.4459 - val_auc_43: 0.8239\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4096 - auc_43: 0.8790 - val_loss: 0.4438 - val_auc_43: 0.8198\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3733 - auc_43: 0.9012 - val_loss: 0.4766 - val_auc_43: 0.8174\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3477 - auc_43: 0.9151 - val_loss: 0.4749 - val_auc_43: 0.8127\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3279 - auc_43: 0.9251 - val_loss: 0.4658 - val_auc_43: 0.8112\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3136 - auc_43: 0.9319 - val_loss: 0.5121 - val_auc_43: 0.8126\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3000 - auc_43: 0.9378 - val_loss: 0.4803 - val_auc_43: 0.8139\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2949 - auc_43: 0.9398 - val_loss: 0.4814 - val_auc_43: 0.8108\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2845 - auc_43: 0.9444 - val_loss: 0.4866 - val_auc_43: 0.8092\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2766 - auc_43: 0.9474 - val_loss: 0.5016 - val_auc_43: 0.8080\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2693 - auc_43: 0.9503 - val_loss: 0.5231 - val_auc_43: 0.8096\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2622 - auc_43: 0.9529 - val_loss: 0.5274 - val_auc_43: 0.8111\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2589 - auc_43: 0.9541 - val_loss: 0.5280 - val_auc_43: 0.8120\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2524 - auc_43: 0.9563 - val_loss: 0.5116 - val_auc_43: 0.8107\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2489 - auc_43: 0.9576 - val_loss: 0.5183 - val_auc_43: 0.8101\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2461 - auc_43: 0.9587 - val_loss: 0.5398 - val_auc_43: 0.8083\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2415 - auc_43: 0.9602 - val_loss: 0.5314 - val_auc_43: 0.8064\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2412 - auc_43: 0.9602 - val_loss: 0.5369 - val_auc_43: 0.8079\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2390 - auc_43: 0.9610 - val_loss: 0.5459 - val_auc_43: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aad7be06a10>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train = pd.concat([ train.loc[:, \"sex_M\":\"W7JWW5\"], train.loc[:, \"1\":\"880\"]], axis=1)\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = pd.concat([ test.loc[:, \"sex_M\":\"W7JWW5\"], test.loc[:, \"1\":\"880\"]],  axis=1)\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.67420476 0.7586097  0.68338391 0.70999247 0.64963343 0.62355512\n",
      " 0.7097004  0.71356015 0.69507478 0.66146923 0.66943592 0.6774588\n",
      " 0.65667534 0.66346378 0.61769966 0.63601055 0.70011988 0.67637753\n",
      " 0.60220805 0.81922878 0.72574054 0.64152344 0.64776049 0.63773688\n",
      " 0.79261932 0.69745144 0.7283892  0.71124802 0.71967669 0.64054075]\n",
      "Macro AUC: 0.6846849669818635\n",
      "MAP per class: [0.33659545 0.35132084 0.2084696  0.14192586 0.33045505 0.17318909\n",
      " 0.81825999 0.55256199 0.81225324 0.32102057 0.8112512  0.21143261\n",
      " 0.65785689 0.55654609 0.58695707 0.4332311  0.11605919 0.39881079\n",
      " 0.8217847  0.18992463 0.41588583 0.46834607 0.6525778  0.70013445\n",
      " 0.3262215  0.82621249 0.40528283 0.28638649 0.21239059 0.76155795]\n",
      "Macro MAP: 0.4628300647192353\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# molecular, chemical, and bio "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = train.loc[:, \"A0A023W3H0\":\"880\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, \"A0A023W3H0\":\"880\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def create_model(optimizer='adam', dropout_rate=0.5, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[AUC(name='auc', multi_label=True)])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(f\"Best parameters found: {grid_result.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_result.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_.model\n",
    "predictions = best_model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate the average AUC across all classes\n",
    "average_auc = np.mean(auc_per_class)\n",
    "print(f'Average AUC: {average_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 0.5287 - auc_44: 0.7799 - val_loss: 0.4681 - val_auc_44: 0.8160\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4586 - auc_44: 0.8434 - val_loss: 0.4623 - val_auc_44: 0.8201\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.4120 - auc_44: 0.8775 - val_loss: 0.4802 - val_auc_44: 0.8140\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3777 - auc_44: 0.8987 - val_loss: 0.4755 - val_auc_44: 0.8126\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3555 - auc_44: 0.9111 - val_loss: 0.4655 - val_auc_44: 0.8175\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3391 - auc_44: 0.9197 - val_loss: 0.4822 - val_auc_44: 0.8116\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3231 - auc_44: 0.9275 - val_loss: 0.4659 - val_auc_44: 0.8127\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3132 - auc_44: 0.9323 - val_loss: 0.4744 - val_auc_44: 0.8133\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.3019 - auc_44: 0.9373 - val_loss: 0.4849 - val_auc_44: 0.8128\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.2920 - auc_44: 0.9415 - val_loss: 0.4969 - val_auc_44: 0.8098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aae2beff3d0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_train = train.loc[:, \"A0A023W3H0\":\"880\"]\n",
    "y_train= train.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "x_test = test.loc[:, \"A0A023W3H0\":\"880\"]\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "\n",
    "y_test = test.loc[:, 'cardiac failure': \"vomiting\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model with AUC as the metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC per class: [0.6603694  0.76025334 0.67870267 0.7626213  0.65354726 0.60746279\n",
      " 0.70610963 0.69000674 0.6682184  0.64910325 0.63995713 0.69490173\n",
      " 0.64458613 0.66375559 0.65314415 0.60384569 0.65500226 0.68083095\n",
      " 0.57936722 0.79214729 0.71789027 0.61984732 0.66188908 0.64066821\n",
      " 0.78044363 0.69536256 0.74110167 0.74538646 0.76922183 0.63654595]\n",
      "Macro AUC: 0.6817429964503344\n",
      "MAP per class: [0.27574786 0.40553551 0.22785641 0.27182593 0.34187916 0.19144561\n",
      " 0.8048589  0.50700614 0.79832689 0.33194854 0.79666096 0.17167347\n",
      " 0.65361258 0.55279729 0.61838686 0.41010172 0.11955342 0.40655027\n",
      " 0.81228887 0.19708759 0.38226711 0.43234359 0.65658761 0.7140441\n",
      " 0.32165012 0.8275756  0.36993465 0.30648867 0.22669841 0.76086255]\n",
      "Macro MAP: 0.46311987950019606\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate AUC for each class\n",
    "auc_per_class = roc_auc_score(y_test, predictions, average=None)\n",
    "print(f\"AUC per class: {auc_per_class}\")\n",
    "\n",
    "# Calculate macro average AUC\n",
    "macro_auc = roc_auc_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "map_per_class = average_precision_score(y_test, predictions, average=None)\n",
    "print(f\"MAP per class: {map_per_class}\")\n",
    "\n",
    "# Calculate macro average MAP\n",
    "macro_map = average_precision_score(y_test, predictions, average='macro')\n",
    "print(f\"Macro MAP: {macro_map}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
